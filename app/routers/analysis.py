"""
è‚¡ç¥¨åˆ†æAPIè·¯ç”±
å¢å¼ºç‰ˆæœ¬ï¼Œæ”¯æŒä¼˜å…ˆçº§ã€è¿›åº¦è·Ÿè¸ªã€ä»»åŠ¡ç®¡ç†ç­‰åŠŸèƒ½
"""

from fastapi import APIRouter, HTTPException, Depends, Query, BackgroundTasks, WebSocket, WebSocketDisconnect
from pydantic import BaseModel, Field
from typing import List, Optional, Dict, Any
from datetime import datetime
import logging
import time
import uuid
import asyncio

from app.routers.auth_db import get_current_user
from app.services.queue_service import get_queue_service, QueueService
# from app.services.analysis_service import get_analysis_service # ç§»é™¤é¡¶å±‚å¯¼å…¥
from app.services.websocket_manager import get_websocket_manager
from app.models.analysis import (
    SingleAnalysisRequest, BatchAnalysisRequest, AnalysisParameters,
    AnalysisTaskResponse, AnalysisBatchResponse, AnalysisHistoryQuery
)
from app.core.config import settings
from tradingagents.utils.runtime_paths import get_analysis_results_dir, resolve_path
from app.utils.timezone import now_utc

router = APIRouter()
logger = logging.getLogger("webapi")

# å…¼å®¹æ€§ï¼šä¿ç•™åŸæœ‰çš„è¯·æ±‚æ¨¡å‹
class SingleAnalyzeRequest(BaseModel):
    symbol: str
    parameters: dict = Field(default_factory=dict)

class BatchAnalyzeRequest(BaseModel):
    symbols: List[str]
    parameters: dict = Field(default_factory=dict)
    title: str = Field(default="æ‰¹é‡åˆ†æ", description="æ‰¹æ¬¡æ ‡é¢˜")
    description: Optional[str] = Field(None, description="æ‰¹æ¬¡æè¿°")

# æ–°ç‰ˆAPIç«¯ç‚¹
@router.post("/single", response_model=Dict[str, Any])
async def submit_single_analysis(
    request: SingleAnalysisRequest,
    background_tasks: BackgroundTasks,
    user: dict = Depends(get_current_user)
):
    """æäº¤å•è‚¡åˆ†æä»»åŠ¡ - ä½¿ç”¨ BackgroundTasks å¼‚æ­¥æ‰§è¡Œ"""
    try:
        logger.info(f"ğŸ¯ æ”¶åˆ°å•è‚¡åˆ†æè¯·æ±‚")
        logger.info(f"ğŸ‘¤ ç”¨æˆ·ä¿¡æ¯: {user}")
        logger.info(f"ğŸ“Š è¯·æ±‚æ•°æ®: {request}")

        # å»¶è¿Ÿå¯¼å…¥ï¼Œé¿å…å¾ªç¯å¼•ç”¨
        from app.services.analysis_service import get_analysis_service

        # ç«‹å³åˆ›å»ºä»»åŠ¡è®°å½•å¹¶è¿”å›ï¼Œä¸ç­‰å¾…æ‰§è¡Œå®Œæˆ
        analysis_service = get_analysis_service()
        result = await analysis_service.create_analysis_task(user["id"], request)

        # æå–å˜é‡ï¼Œé¿å…é—­åŒ…é—®é¢˜
        task_id = result["task_id"]
        user_id = user["id"]

        # å®šä¹‰ä¸€ä¸ªåŒ…è£…å‡½æ•°æ¥è¿è¡Œå¼‚æ­¥ä»»åŠ¡
        async def run_analysis_task():
            """åŒ…è£…å‡½æ•°ï¼šåœ¨åå°è¿è¡Œåˆ†æä»»åŠ¡"""
            try:
                logger.info(f"ğŸš€ [BackgroundTask] å¼€å§‹æ‰§è¡Œåˆ†æä»»åŠ¡: {task_id}")
                logger.info(f"ğŸ“ [BackgroundTask] task_id={task_id}, user_id={user_id}")
                logger.info(f"ğŸ“ [BackgroundTask] request={request}")

                # é‡æ–°è·å–æœåŠ¡å®ä¾‹ï¼Œç¡®ä¿åœ¨æ­£ç¡®çš„ä¸Šä¸‹æ–‡ä¸­
                logger.info(f"ğŸ”§ [BackgroundTask] æ­£åœ¨è·å–æœåŠ¡å®ä¾‹...")
                # å»¶è¿Ÿå¯¼å…¥ï¼Œé¿å…å¾ªç¯å¼•ç”¨
                from app.services.analysis_service import get_analysis_service
                service = get_analysis_service()
                logger.info(f"âœ… [BackgroundTask] æœåŠ¡å®ä¾‹è·å–æˆåŠŸ: {id(service)}")

                logger.info(f"ğŸš€ [BackgroundTask] å‡†å¤‡è°ƒç”¨ execute_analysis_background...")
                await service.execute_analysis_background(
                    task_id,
                    user_id,
                    request
                )
                logger.info(f"âœ… [BackgroundTask] åˆ†æä»»åŠ¡å®Œæˆ: {task_id}")
            except Exception as e:
                logger.error(f"âŒ [BackgroundTask] åˆ†æä»»åŠ¡å¤±è´¥: {task_id}, é”™è¯¯: {e}", exc_info=True)

        # ä½¿ç”¨ BackgroundTasks æ‰§è¡Œå¼‚æ­¥ä»»åŠ¡
        background_tasks.add_task(run_analysis_task)

        logger.info(f"âœ… åˆ†æä»»åŠ¡å·²åœ¨åå°å¯åŠ¨: {result}")

        return {
            "success": True,
            "data": result,
            "message": "åˆ†æä»»åŠ¡å·²åœ¨åå°å¯åŠ¨"
        }
    except Exception as e:
        logger.error(f"âŒ æäº¤å•è‚¡åˆ†æä»»åŠ¡å¤±è´¥: {e}")
        raise HTTPException(status_code=400, detail=str(e))


# æµ‹è¯•è·¯ç”± - éªŒè¯è·¯ç”±æ˜¯å¦è¢«æ­£ç¡®æ³¨å†Œ
@router.get("/test-route")
async def test_route():
    """æµ‹è¯•è·¯ç”±æ˜¯å¦å·¥ä½œ"""
    logger.info("ğŸ§ª æµ‹è¯•è·¯ç”±è¢«è°ƒç”¨äº†ï¼")
    return {"message": "æµ‹è¯•è·¯ç”±å·¥ä½œæ­£å¸¸", "timestamp": time.time()}

@router.get("/tasks/{task_id}/status", response_model=Dict[str, Any])
async def get_task_status_new(
    task_id: str,
    user: dict = Depends(get_current_user)
):
    """è·å–åˆ†æä»»åŠ¡çŠ¶æ€ï¼ˆæ–°ç‰ˆå¼‚æ­¥å®ç°ï¼‰"""
    try:
        # å»¶è¿Ÿå¯¼å…¥ï¼Œé¿å…å¾ªç¯å¼•ç”¨
        from app.services.analysis_service import get_analysis_service
        analysis_service = get_analysis_service()

        result = await analysis_service.get_task_status(task_id)
        
        if result:
            return {
                "success": True,
                "data": result,
                "message": "ä»»åŠ¡çŠ¶æ€è·å–æˆåŠŸ"
            }
        else:
            # å†…å­˜ä¸­æ²¡æœ‰æ‰¾åˆ°ï¼Œå°è¯•ä»MongoDBä¸­æŸ¥æ‰¾
            logger.info(f"ğŸ“Š [STATUS] å†…å­˜ä¸­æœªæ‰¾åˆ°ï¼Œå°è¯•ä»MongoDBæŸ¥æ‰¾: {task_id}")

            from app.core.database import get_mongo_db
            db = get_mongo_db()

            # é¦–å…ˆä»analysis_tasksé›†åˆä¸­æŸ¥æ‰¾ï¼ˆæ­£åœ¨è¿›è¡Œçš„ä»»åŠ¡ï¼‰
            task_result = await db.analysis_tasks.find_one({"task_id": task_id})

            if task_result:
                logger.info(f"âœ… [STATUS] ä»analysis_tasksæ‰¾åˆ°ä»»åŠ¡: {task_id}")

                # æ„é€ çŠ¶æ€å“åº”ï¼ˆæ­£åœ¨è¿›è¡Œçš„ä»»åŠ¡ï¼‰
                status = task_result.get("status", "pending")
                progress = task_result.get("progress", 0)

                # è®¡ç®—æ—¶é—´ä¿¡æ¯
                start_time = task_result.get("started_at") or task_result.get("created_at")
                current_time = now_utc()
                elapsed_time = 0
                if start_time:
                    elapsed_time = (current_time - start_time).total_seconds()

                status_data = {
                    "task_id": task_id,
                    "status": status,
                    "progress": progress,
                    "message": f"ä»»åŠ¡{status}ä¸­...",
                    "current_step": status,
                    "start_time": start_time,
                    "end_time": task_result.get("completed_at"),
                    "elapsed_time": elapsed_time,
                    "remaining_time": 0,  # æ— æ³•å‡†ç¡®ä¼°ç®—
                    "estimated_total_time": 0,
                    "symbol": task_result.get("symbol") or task_result.get("stock_code"),
                    "stock_code": task_result.get("symbol") or task_result.get("stock_code"),  # å…¼å®¹å­—æ®µ
                    "stock_symbol": task_result.get("symbol") or task_result.get("stock_code"),
                    "source": "mongodb_tasks"  # æ ‡è®°æ•°æ®æ¥æº
                }

                return {
                    "success": True,
                    "data": status_data,
                    "message": "ä»»åŠ¡çŠ¶æ€è·å–æˆåŠŸï¼ˆä»ä»»åŠ¡è®°å½•æ¢å¤ï¼‰"
                }

            # å¦‚æœanalysis_tasksä¸­æ²¡æœ‰æ‰¾åˆ°ï¼Œå†ä»analysis_reportsé›†åˆä¸­æŸ¥æ‰¾ï¼ˆå·²å®Œæˆçš„ä»»åŠ¡ï¼‰
            mongo_result = await db.analysis_reports.find_one({"task_id": task_id})

            if not mongo_result:
                # å…¼å®¹æ—§æ•°æ®ï¼šæ—§è®°å½•å¯èƒ½æ²¡æœ‰ task_idï¼Œå°è¯•é€šè¿‡ analysis_id æŸ¥æ‰¾
                tasks_doc_for_id = await db.analysis_tasks.find_one(
                    {"task_id": task_id},
                    {"result.analysis_id": 1}
                )
                if tasks_doc_for_id:
                    analysis_id = tasks_doc_for_id.get("result", {}).get("analysis_id")
                    if analysis_id:
                        logger.info(f"ğŸ” [STATUS] æŒ‰analysis_idå…œåº•æŸ¥è¯¢: {analysis_id}")
                        mongo_result = await db.analysis_reports.find_one({"analysis_id": analysis_id})

            if mongo_result:
                logger.info(f"âœ… [STATUS] ä»analysis_reportsæ‰¾åˆ°ä»»åŠ¡: {task_id}")

                # æ„é€ çŠ¶æ€å“åº”ï¼ˆæ¨¡æ‹Ÿå·²å®Œæˆçš„ä»»åŠ¡ï¼‰
                # è®¡ç®—å·²å®Œæˆä»»åŠ¡çš„æ—¶é—´ä¿¡æ¯
                start_time = mongo_result.get("created_at")
                end_time = mongo_result.get("updated_at")
                elapsed_time = 0
                if start_time and end_time:
                    elapsed_time = (end_time - start_time).total_seconds()

                status_data = {
                    "task_id": task_id,
                    "status": "completed",
                    "progress": 100,
                    "message": "åˆ†æå®Œæˆï¼ˆä»å†å²è®°å½•æ¢å¤ï¼‰",
                    "current_step": "completed",
                    "start_time": start_time,
                    "end_time": end_time,
                    "elapsed_time": elapsed_time,
                    "remaining_time": 0,
                    "estimated_total_time": elapsed_time,  # å·²å®Œæˆä»»åŠ¡çš„æ€»æ—¶é•¿å°±æ˜¯å·²ç”¨æ—¶é—´
                    "stock_code": mongo_result.get("stock_symbol"),
                    "stock_symbol": mongo_result.get("stock_symbol"),
                    "analysts": mongo_result.get("analysts", []),
                    "research_depth": mongo_result.get("research_depth", "å¿«é€Ÿ"),
                    "source": "mongodb_reports"  # æ ‡è®°æ•°æ®æ¥æº
                }

                return {
                    "success": True,
                    "data": status_data,
                    "message": "ä»»åŠ¡çŠ¶æ€è·å–æˆåŠŸï¼ˆä»å†å²è®°å½•æ¢å¤ï¼‰"
                }
            else:
                logger.warning(f"âŒ [STATUS] MongoDBä¸­ä¹Ÿæœªæ‰¾åˆ°ä»»åŠ¡: {task_id}")
                raise HTTPException(status_code=404, detail=f"ä»»åŠ¡ä¸å­˜åœ¨: {task_id}")

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ è·å–ä»»åŠ¡çŠ¶æ€å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@router.get("/tasks/{task_id}/result", response_model=Dict[str, Any])
async def get_task_result(
    task_id: str,
    user: dict = Depends(get_current_user)
):
    """è·å–åˆ†æä»»åŠ¡ç»“æœ"""
    try:
        logger.info(f"ğŸ” [RESULT] è·å–ä»»åŠ¡ç»“æœ: {task_id}")
        
        # å»¶è¿Ÿå¯¼å…¥ï¼Œé¿å…å¾ªç¯å¼•ç”¨
        from app.services.analysis_service import get_analysis_service
        analysis_service = get_analysis_service()
        
        task_status = await analysis_service.get_task_status(task_id)

        result_data = None

        if task_status and task_status.get('status') == 'completed':
            # ä»å†…å­˜ä¸­è·å–ç»“æœæ•°æ®
            result_data = task_status.get('result_data')
            logger.info(f"ğŸ“Š [RESULT] ä»å†…å­˜ä¸­è·å–åˆ°ç»“æœæ•°æ®")

            # ğŸ” è°ƒè¯•ï¼šæ£€æŸ¥å†…å­˜ä¸­çš„æ•°æ®ç»“æ„
            if result_data:
                logger.info(f"ğŸ“Š [RESULT] å†…å­˜æ•°æ®é”®: {list(result_data.keys())}")
                logger.info(f"ğŸ“Š [RESULT] å†…å­˜ä¸­æœ‰decisionå­—æ®µ: {bool(result_data.get('decision'))}")
                logger.info(f"ğŸ“Š [RESULT] å†…å­˜ä¸­summaryé•¿åº¦: {len(result_data.get('summary', ''))}")
                logger.info(f"ğŸ“Š [RESULT] å†…å­˜ä¸­recommendationé•¿åº¦: {len(result_data.get('recommendation', ''))}")
                if result_data.get('decision'):
                    decision = result_data['decision']
                    logger.info(f"ğŸ“Š [RESULT] å†…å­˜decisionå†…å®¹: action={decision.get('action')}, target_price={decision.get('target_price')}")
            else:
                logger.warning(f"âš ï¸ [RESULT] å†…å­˜ä¸­result_dataä¸ºç©º")

        if not result_data:
            # å†…å­˜ä¸­æ²¡æœ‰æ‰¾åˆ°ï¼Œå°è¯•ä»MongoDBä¸­æŸ¥æ‰¾
            logger.info(f"ğŸ“Š [RESULT] å†…å­˜ä¸­æœªæ‰¾åˆ°ï¼Œå°è¯•ä»MongoDBæŸ¥æ‰¾: {task_id}")

            from app.core.database import get_mongo_db
            db = get_mongo_db()

            # ä»analysis_reportsé›†åˆä¸­æŸ¥æ‰¾ï¼ˆä¼˜å…ˆä½¿ç”¨ task_id åŒ¹é…ï¼‰
            mongo_result = await db.analysis_reports.find_one({"task_id": task_id})

            if not mongo_result:
                # å…¼å®¹æ—§æ•°æ®ï¼šæ—§è®°å½•å¯èƒ½æ²¡æœ‰ task_idï¼Œä½† analysis_id å­˜åœ¨äº analysis_tasks.result
                tasks_doc_for_id = await db.analysis_tasks.find_one({"task_id": task_id}, {"result.analysis_id": 1})
                analysis_id = tasks_doc_for_id.get("result", {}).get("analysis_id") if tasks_doc_for_id else None
                if analysis_id:
                    logger.info(f"ğŸ” [RESULT] æŒ‰analysis_idå…œåº•æŸ¥è¯¢ analysis_reports: {analysis_id}")
                    mongo_result = await db.analysis_reports.find_one({"analysis_id": analysis_id})

            if mongo_result:
                logger.info(f"âœ… [RESULT] ä»MongoDBæ‰¾åˆ°ç»“æœ: {task_id}")

                # ç›´æ¥ä½¿ç”¨MongoDBä¸­çš„æ•°æ®ç»“æ„ï¼ˆä¸webç›®å½•ä¿æŒä¸€è‡´ï¼‰
                result_data = {
                    "analysis_id": mongo_result.get("analysis_id"),
                    "stock_symbol": mongo_result.get("stock_symbol"),
                    "stock_code": mongo_result.get("stock_symbol"),  # å…¼å®¹æ€§
                    "analysis_date": mongo_result.get("analysis_date"),
                    "summary": mongo_result.get("summary", ""),
                    "recommendation": mongo_result.get("recommendation", ""),
                    "confidence_score": mongo_result.get("confidence_score", 0.0),
                    "risk_level": mongo_result.get("risk_level", "ä¸­ç­‰"),
                    "key_points": mongo_result.get("key_points", []),
                    "execution_time": mongo_result.get("execution_time", 0),
                    "tokens_used": mongo_result.get("tokens_used", 0),
                    "analysts": mongo_result.get("analysts", []),
                    "research_depth": mongo_result.get("research_depth", "å¿«é€Ÿ"),
                    "reports": mongo_result.get("reports", {}),
                    "created_at": mongo_result.get("created_at"),
                    "updated_at": mongo_result.get("updated_at"),
                    "status": mongo_result.get("status", "completed"),
                    "decision": mongo_result.get("decision", {}),
                    "source": "mongodb"  # æ ‡è®°æ•°æ®æ¥æº
                }

                # æ·»åŠ è°ƒè¯•ä¿¡æ¯
                logger.info(f"ğŸ“Š [RESULT] MongoDBæ•°æ®ç»“æ„: {list(result_data.keys())}")
                logger.info(f"ğŸ“Š [RESULT] MongoDB summaryé•¿åº¦: {len(result_data['summary'])}")
                logger.info(f"ğŸ“Š [RESULT] MongoDB recommendationé•¿åº¦: {len(result_data['recommendation'])}")
                logger.info(f"ğŸ“Š [RESULT] MongoDB decisionå­—æ®µ: {bool(result_data.get('decision'))}")
                if result_data.get('decision'):
                    decision = result_data['decision']
                    logger.info(f"ğŸ“Š [RESULT] MongoDB decisionå†…å®¹: action={decision.get('action')}, target_price={decision.get('target_price')}, confidence={decision.get('confidence')}")
            else:
                # å…œåº•ï¼šanalysis_tasks é›†åˆä¸­çš„ result å­—æ®µ
                tasks_doc = await db.analysis_tasks.find_one(
                    {"task_id": task_id},
                    {"result": 1, "symbol": 1, "stock_code": 1, "created_at": 1, "completed_at": 1}
                )
                if tasks_doc and tasks_doc.get("result"):
                    r = tasks_doc["result"] or {}
                    logger.info("âœ… [RESULT] ä»analysis_tasks.result æ‰¾åˆ°ç»“æœ")
                    # è·å–è‚¡ç¥¨ä»£ç  (ä¼˜å…ˆä½¿ç”¨symbol)
                    symbol = (tasks_doc.get("symbol") or tasks_doc.get("stock_code") or
                             r.get("stock_symbol") or r.get("stock_code"))
                    result_data = {
                        "analysis_id": r.get("analysis_id"),
                        "stock_symbol": symbol,
                        "stock_code": symbol,  # å…¼å®¹å­—æ®µ
                        "analysis_date": r.get("analysis_date"),
                        "summary": r.get("summary", ""),
                        "recommendation": r.get("recommendation", ""),
                        "confidence_score": r.get("confidence_score", 0.0),
                        "risk_level": r.get("risk_level", "ä¸­ç­‰"),
                        "key_points": r.get("key_points", []),
                        "execution_time": r.get("execution_time", 0),
                        "tokens_used": r.get("tokens_used", 0),
                        "analysts": r.get("analysts", []),
                        "research_depth": r.get("research_depth", "å¿«é€Ÿ"),
                        "reports": r.get("reports", {}),
                        "state": r.get("state", {}),
                        "detailed_analysis": r.get("detailed_analysis", {}),
                        "created_at": tasks_doc.get("created_at"),
                        "updated_at": tasks_doc.get("completed_at"),
                        "status": r.get("status", "completed"),
                        "decision": r.get("decision", {}),
                        "source": "analysis_tasks"  # æ•°æ®æ¥æºæ ‡è®°
                    }

        if not result_data:
            logger.warning(f"âŒ [RESULT] æ‰€æœ‰æ•°æ®æºéƒ½æœªæ‰¾åˆ°ç»“æœ: {task_id}")
            raise HTTPException(status_code=404, detail="åˆ†æç»“æœä¸å­˜åœ¨")

        if not result_data:
            raise HTTPException(status_code=404, detail="åˆ†æç»“æœä¸å­˜åœ¨")

        # å¤„ç†reportså­—æ®µ - å¦‚æœæ²¡æœ‰reportså­—æ®µï¼Œä¼˜å…ˆå°è¯•ä»æ–‡ä»¶ç³»ç»ŸåŠ è½½ï¼Œå…¶æ¬¡ä»stateä¸­æå–
        if 'reports' not in result_data or not result_data['reports']:
            import os
            from pathlib import Path

            stock_symbol = result_data.get('stock_symbol') or result_data.get('stock_code')
            # analysis_date å¯èƒ½æ˜¯æ—¥æœŸæˆ–æ—¶é—´æˆ³å­—ç¬¦ä¸²ï¼Œè¿™é‡Œåªå–æ—¥æœŸéƒ¨åˆ†
            analysis_date_raw = result_data.get('analysis_date')
            analysis_date = str(analysis_date_raw)[:10] if analysis_date_raw else None

            loaded_reports = {}
            try:
                # 1) ä¼˜å…ˆç¯å¢ƒå˜é‡ï¼Œå…¶æ¬¡ç»Ÿä¸€ runtime è·¯å¾„
                runtime_base = settings.RUNTIME_BASE_DIR
                base_env = os.getenv('TRADINGAGENTS_RESULTS_DIR')
                if base_env:
                    base_path = resolve_path(base_env, runtime_base)
                else:
                    base_path = get_analysis_results_dir(runtime_base)

                candidate_dirs = []
                if stock_symbol and analysis_date:
                    candidate_dirs.append(base_path / stock_symbol / analysis_date / 'reports')
                    candidate_dirs.append(
                        get_analysis_results_dir(runtime_base) / 'detailed' / stock_symbol / analysis_date / 'reports'
                    )

                for d in candidate_dirs:
                    if d.exists() and d.is_dir():
                        for f in d.glob('*.md'):
                            try:
                                content = f.read_text(encoding='utf-8')
                                if content and content.strip():
                                    loaded_reports[f.stem] = content.strip()
                            except Exception:
                                pass
                if loaded_reports:
                    result_data['reports'] = loaded_reports
                    # è‹¥ summary / recommendation ç¼ºå¤±ï¼Œå°è¯•ä»åŒåæŠ¥å‘Šè¡¥å…¨
                    if not result_data.get('summary') and loaded_reports.get('summary'):
                        result_data['summary'] = loaded_reports.get('summary')
                    if not result_data.get('recommendation') and loaded_reports.get('recommendation'):
                        result_data['recommendation'] = loaded_reports.get('recommendation')
                    logger.info(f"ğŸ“ [RESULT] ä»æ–‡ä»¶ç³»ç»ŸåŠ è½½åˆ° {len(loaded_reports)} ä¸ªæŠ¥å‘Š: {list(loaded_reports.keys())}")
            except Exception as fs_err:
                logger.warning(f"âš ï¸ [RESULT] ä»æ–‡ä»¶ç³»ç»ŸåŠ è½½æŠ¥å‘Šå¤±è´¥: {fs_err}")

            if 'reports' not in result_data or not result_data['reports']:
                logger.info(f"ğŸ“Š [RESULT] reportså­—æ®µç¼ºå¤±ï¼Œå°è¯•ä»stateä¸­æå–")

                # ä»stateä¸­æå–æŠ¥å‘Šå†…å®¹
                reports = {}
                state = result_data.get('state', {})

                if isinstance(state, dict):
                    # ğŸ”¥ åŠ¨æ€å‘ç°æ‰€æœ‰ *_report å­—æ®µï¼Œè€Œéä½¿ç”¨ç¡¬ç¼–ç åˆ—è¡¨
                    # è¿™æ ·å¯ä»¥è‡ªåŠ¨æ”¯æŒæ–°æ·»åŠ çš„åˆ†æå¸ˆæŠ¥å‘Š
                    known_non_report_keys = [
                        "trader_investment_plan", "investment_plan", "final_trade_decision"
                    ]
                    
                    # ä»stateä¸­åŠ¨æ€æå–æ‰€æœ‰æŠ¥å‘Šå†…å®¹
                    for key in state.keys():
                        # åŒ¹é…æ‰€æœ‰ *_report å­—æ®µæˆ–å·²çŸ¥çš„é _report åç¼€çš„æŠ¥å‘Šå­—æ®µ
                        if key.endswith("_report") or key in known_non_report_keys:
                            value = state.get(key, "")
                            if isinstance(value, str) and len(value.strip()) > 10:
                                reports[key] = value.strip()
                    
                    logger.info(f"ğŸ“Š [RESULT] åŠ¨æ€å‘ç° {len(reports)} ä¸ªæŠ¥å‘Šå­—æ®µ: {list(reports.keys())}")

                    # å¤„ç†ç ”ç©¶å›¢é˜Ÿè¾©è®ºçŠ¶æ€æŠ¥å‘Š
                    investment_debate_state = state.get('investment_debate_state', {})
                    if isinstance(investment_debate_state, dict):
                        # æå–å¤šå¤´ç ”ç©¶å‘˜å†å²
                        bull_content = investment_debate_state.get('bull_history', "")
                        if isinstance(bull_content, str) and len(bull_content.strip()) > 10:
                            reports['bull_researcher'] = bull_content.strip()

                        # æå–ç©ºå¤´ç ”ç©¶å‘˜å†å²
                        bear_content = investment_debate_state.get('bear_history', "")
                        if isinstance(bear_content, str) and len(bear_content.strip()) > 10:
                            reports['bear_researcher'] = bear_content.strip()

                        # æå–ç ”ç©¶ç»ç†å†³ç­–
                        judge_decision = investment_debate_state.get('judge_decision', "")
                        if isinstance(judge_decision, str) and len(judge_decision.strip()) > 10:
                            reports['research_team_decision'] = judge_decision.strip()

                    # å¤„ç†é£é™©ç®¡ç†å›¢é˜Ÿè¾©è®ºçŠ¶æ€æŠ¥å‘Š
                    risk_debate_state = state.get('risk_debate_state', {})
                    if isinstance(risk_debate_state, dict):
                        # æå–æ¿€è¿›åˆ†æå¸ˆå†å²
                        risky_content = risk_debate_state.get('risky_history', "")
                        if isinstance(risky_content, str) and len(risky_content.strip()) > 10:
                            reports['risky_analyst'] = risky_content.strip()

                        # æå–ä¿å®ˆåˆ†æå¸ˆå†å²
                        safe_content = risk_debate_state.get('safe_history', "")
                        if isinstance(safe_content, str) and len(safe_content.strip()) > 10:
                            reports['safe_analyst'] = safe_content.strip()

                        # æå–ä¸­æ€§åˆ†æå¸ˆå†å²
                        neutral_content = risk_debate_state.get('neutral_history', "")
                        if isinstance(neutral_content, str) and len(neutral_content.strip()) > 10:
                            reports['neutral_analyst'] = neutral_content.strip()

                        # æå–æŠ•èµ„ç»„åˆç»ç†å†³ç­–
                        risk_decision = risk_debate_state.get('judge_decision', "")
                        if isinstance(risk_decision, str) and len(risk_decision.strip()) > 10:
                            reports['risk_management_decision'] = risk_decision.strip()

                    logger.info(f"ğŸ“Š [RESULT] ä»stateä¸­æå–åˆ° {len(reports)} ä¸ªæŠ¥å‘Š: {list(reports.keys())}")
                    result_data['reports'] = reports
                else:
                    logger.warning(f"âš ï¸ [RESULT] stateå­—æ®µä¸æ˜¯å­—å…¸ç±»å‹: {type(state)}")

        # ç¡®ä¿reportså­—æ®µä¸­çš„æ‰€æœ‰å†…å®¹éƒ½æ˜¯å­—ç¬¦ä¸²ç±»å‹
        if 'reports' in result_data and result_data['reports']:
            reports = result_data['reports']
            logger.info(f"ğŸ“Š [RESULT] æ¸…ç†å‰reportså­—æ®µåŒ…å« {len(reports)} ä¸ªæŠ¥å‘Š: {list(reports.keys())}")
            if isinstance(reports, dict):
                # ç¡®ä¿æ¯ä¸ªæŠ¥å‘Šå†…å®¹éƒ½æ˜¯å­—ç¬¦ä¸²ä¸”ä¸ä¸ºç©º
                cleaned_reports = {}
                for key, value in reports.items():
                    if isinstance(value, str) and value.strip():
                        # ç¡®ä¿å­—ç¬¦ä¸²ä¸ä¸ºç©º
                        cleaned_reports[key] = value.strip()
                    elif value is not None:
                        # å¦‚æœä¸æ˜¯å­—ç¬¦ä¸²ï¼Œè½¬æ¢ä¸ºå­—ç¬¦ä¸²
                        str_value = str(value).strip()
                        if str_value:  # åªä¿å­˜éç©ºå­—ç¬¦ä¸²
                            cleaned_reports[key] = str_value
                    # å¦‚æœvalueä¸ºNoneæˆ–ç©ºå­—ç¬¦ä¸²ï¼Œåˆ™è·³è¿‡è¯¥æŠ¥å‘Š

                result_data['reports'] = cleaned_reports
                logger.info(f"ğŸ“Š [RESULT] æ¸…ç†åreportså­—æ®µåŒ…å« {len(cleaned_reports)} ä¸ªæœ‰æ•ˆæŠ¥å‘Š: {list(cleaned_reports.keys())}")

                # å¦‚æœæ¸…ç†åæ²¡æœ‰æœ‰æ•ˆæŠ¥å‘Šï¼Œè®¾ç½®ä¸ºç©ºå­—å…¸
                if not cleaned_reports:
                    logger.warning(f"âš ï¸ [RESULT] æ¸…ç†åæ²¡æœ‰æœ‰æ•ˆæŠ¥å‘Š")
                    result_data['reports'] = {}
            else:
                logger.warning(f"âš ï¸ [RESULT] reportså­—æ®µä¸æ˜¯å­—å…¸ç±»å‹: {type(reports)}")
                result_data['reports'] = {}

        # è¡¥å…¨å…³é”®å­—æ®µï¼šrecommendation/summary/key_points
        try:
            reports = result_data.get('reports', {}) or {}
            decision = result_data.get('decision', {}) or {}

            # recommendation ä¼˜å…ˆä½¿ç”¨å†³ç­–æ‘˜è¦æˆ–æŠ¥å‘Šä¸­çš„å†³ç­–
            if not result_data.get('recommendation'):
                rec_candidates = []
                if isinstance(decision, dict) and decision.get('action'):
                    parts = [
                        f"æ“ä½œ: {decision.get('action')}",
                        f"ç›®æ ‡ä»·: {decision.get('target_price')}" if decision.get('target_price') else None,
                        f"ç½®ä¿¡åº¦: {decision.get('confidence')}" if decision.get('confidence') is not None else None
                    ]
                    rec_candidates.append("ï¼›".join([p for p in parts if p]))
                # ä»æŠ¥å‘Šä¸­å…œåº•
                for k in ['final_trade_decision', 'investment_plan']:
                    v = reports.get(k)
                    if isinstance(v, str) and len(v.strip()) > 10:
                        rec_candidates.append(v.strip())
                if rec_candidates:
                    # å–æœ€æœ‰ä¿¡æ¯é‡çš„ä¸€æ¡ï¼ˆæœ€é•¿ï¼‰
                    result_data['recommendation'] = max(rec_candidates, key=len)[:2000]

            # summary ä»è‹¥å¹²æŠ¥å‘Šæ‹¼æ¥ç”Ÿæˆ
            # ğŸ”¥ åŠ¨æ€å‘ç°æ‰€æœ‰ *_report å­—æ®µï¼Œä¼˜å…ˆä½¿ç”¨æ ¸å¿ƒæŠ¥å‘Šï¼Œç„¶åæ·»åŠ å…¶ä»–æŠ¥å‘Š
            if not result_data.get('summary'):
                sum_candidates = []
                # ä¼˜å…ˆä½¿ç”¨æ ¸å¿ƒæŠ¥å‘Š
                core_reports = ['market_report', 'fundamentals_report', 'sentiment_report', 'news_report']
                for k in core_reports:
                    v = reports.get(k)
                    if isinstance(v, str) and len(v.strip()) > 50:
                        sum_candidates.append(v.strip())
                # æ·»åŠ å…¶ä»–åŠ¨æ€æŠ¥å‘Šï¼ˆå¦‚æœæ ¸å¿ƒæŠ¥å‘Šä¸è¶³ï¼‰
                if len(sum_candidates) < 2:
                    for k, v in reports.items():
                        if k.endswith('_report') and k not in core_reports:
                            if isinstance(v, str) and len(v.strip()) > 50:
                                sum_candidates.append(v.strip())
                                if len(sum_candidates) >= 4:
                                    break
                if sum_candidates:
                    result_data['summary'] = ("\n\n".join(sum_candidates))[:3000]

            # key_points å…œåº•
            if not result_data.get('key_points'):
                kp = []
                if isinstance(decision, dict):
                    if decision.get('action'):
                        kp.append(f"æ“ä½œå»ºè®®: {decision.get('action')}")
                    if decision.get('target_price'):
                        kp.append(f"ç›®æ ‡ä»·: {decision.get('target_price')}")
                    if decision.get('confidence') is not None:
                        kp.append(f"ç½®ä¿¡åº¦: {decision.get('confidence')}")
                # ä»reportsä¸­æˆªå–å‰å‡ å¥ä½œä¸ºè¦ç‚¹
                for k in ['investment_plan', 'final_trade_decision']:
                    v = reports.get(k)
                    if isinstance(v, str) and len(v.strip()) > 10:
                        kp.append(v.strip()[:120])
                if kp:
                    result_data['key_points'] = kp[:5]
        except Exception as fill_err:
            logger.warning(f"âš ï¸ [RESULT] è¡¥å…¨å…³é”®å­—æ®µæ—¶å‡ºé”™: {fill_err}")


        # è¿›ä¸€æ­¥å…œåº•ï¼šä» detailed_analysis æ¨æ–­å¹¶è¡¥å…¨
        try:
            if not result_data.get('summary') or not result_data.get('recommendation') or not result_data.get('reports'):
                da = result_data.get('detailed_analysis')
                # è‹¥reportsä»ä¸ºç©ºï¼Œæ”¾å…¥ä¸€ä»½åŸå§‹è¯¦ç»†åˆ†æï¼Œä¾¿äºå‰ç«¯â€œæŸ¥çœ‹æŠ¥å‘Šè¯¦æƒ…â€
                if (not result_data.get('reports')) and isinstance(da, str) and len(da.strip()) > 20:
                    result_data['reports'] = {'detailed_analysis': da.strip()}
                elif (not result_data.get('reports')) and isinstance(da, dict) and da:
                    # å°†å­—å…¸çš„é•¿æ–‡æœ¬é¡¹æ”¾å…¥reports
                    extracted = {}
                    for k, v in da.items():
                        if isinstance(v, str) and len(v.strip()) > 20:
                            extracted[k] = v.strip()
                    if extracted:
                        result_data['reports'] = extracted

                # è¡¥ summary
                if not result_data.get('summary'):
                    if isinstance(da, str) and da.strip():
                        result_data['summary'] = da.strip()[:3000]
                    elif isinstance(da, dict) and da:
                        # å–æœ€é•¿çš„æ–‡æœ¬ä½œä¸ºæ‘˜è¦
                        texts = [v.strip() for v in da.values() if isinstance(v, str) and v.strip()]
                        if texts:
                            result_data['summary'] = max(texts, key=len)[:3000]

                # è¡¥ recommendation
                if not result_data.get('recommendation'):
                    rec = None
                    if isinstance(da, str):
                        # ç®€å•åŸºäºå…³é”®å­—æå–åŒ…å«â€œå»ºè®®â€çš„æ®µè½
                        import re
                        m = re.search(r'(æŠ•èµ„å»ºè®®|å»ºè®®|ç»“è®º)[:ï¼š]?\s*(.+)', da)
                        if m:
                            rec = m.group(0)
                    elif isinstance(da, dict):
                        for key in ['final_trade_decision', 'investment_plan', 'ç»“è®º', 'å»ºè®®']:
                            v = da.get(key)
                            if isinstance(v, str) and len(v.strip()) > 10:
                                rec = v.strip()
                                break
                    if rec:
                        result_data['recommendation'] = rec[:2000]
        except Exception as da_err:
            logger.warning(f"âš ï¸ [RESULT] ä»detailed_analysisè¡¥å…¨å¤±è´¥: {da_err}")

        # ä¸¥æ ¼çš„æ•°æ®æ ¼å¼åŒ–å’ŒéªŒè¯
        def safe_string(value, default=""):
            """å®‰å…¨åœ°è½¬æ¢ä¸ºå­—ç¬¦ä¸²"""
            if value is None:
                return default
            if isinstance(value, str):
                return value
            return str(value)

        def safe_number(value, default=0):
            """å®‰å…¨åœ°è½¬æ¢ä¸ºæ•°å­—"""
            if value is None:
                return default
            if isinstance(value, (int, float)):
                return value
            try:
                return float(value)
            except (ValueError, TypeError):
                return default

        def safe_list(value, default=None):
            """å®‰å…¨åœ°è½¬æ¢ä¸ºåˆ—è¡¨"""
            if default is None:
                default = []
            if value is None:
                return default
            if isinstance(value, list):
                return value
            return default

        def safe_dict(value, default=None):
            """å®‰å…¨åœ°è½¬æ¢ä¸ºå­—å…¸"""
            if default is None:
                default = {}
            if value is None:
                return default
            if isinstance(value, dict):
                return value
            return default

        # ğŸ” è°ƒè¯•ï¼šæ£€æŸ¥æœ€ç»ˆæ„å»ºå‰çš„result_data
        logger.info(f"ğŸ” [FINAL] æ„å»ºæœ€ç»ˆç»“æœå‰ï¼Œresult_dataé”®: {list(result_data.keys())}")
        logger.info(f"ğŸ” [FINAL] result_dataä¸­æœ‰decision: {bool(result_data.get('decision'))}")
        if result_data.get('decision'):
            logger.info(f"ğŸ” [FINAL] decisionå†…å®¹: {result_data['decision']}")

        # æ„å»ºä¸¥æ ¼éªŒè¯çš„ç»“æœæ•°æ®
        final_result_data = {
            "analysis_id": safe_string(result_data.get("analysis_id"), "unknown"),
            "stock_symbol": safe_string(result_data.get("stock_symbol"), "UNKNOWN"),
            "stock_code": safe_string(result_data.get("stock_code"), "UNKNOWN"),
            "analysis_date": safe_string(result_data.get("analysis_date"), "2025-08-20"),
            "summary": safe_string(result_data.get("summary"), "åˆ†ææ‘˜è¦æš‚æ— "),
            "recommendation": safe_string(result_data.get("recommendation"), "æŠ•èµ„å»ºè®®æš‚æ— "),
            "confidence_score": safe_number(result_data.get("confidence_score"), 0.0),
            "risk_level": safe_string(result_data.get("risk_level"), "ä¸­ç­‰"),
            "key_points": safe_list(result_data.get("key_points")),
            "execution_time": safe_number(result_data.get("execution_time"), 0),
            "tokens_used": safe_number(result_data.get("tokens_used"), 0),
            "analysts": safe_list(result_data.get("analysts")),
            "research_depth": safe_string(result_data.get("research_depth"), "å¿«é€Ÿ"),
            "detailed_analysis": safe_dict(result_data.get("detailed_analysis")),
            "state": safe_dict(result_data.get("state")),
            # ğŸ”¥ å…³é”®ä¿®å¤ï¼šæ·»åŠ decisionå­—æ®µï¼
            "decision": safe_dict(result_data.get("decision")),
            # ğŸ”¥ æ·»åŠ ç»“æ„åŒ–æ€»ç»“å­—æ®µï¼ˆç¬¬å››é˜¶æ®µç”Ÿæˆçš„å…³é”®æŒ‡æ ‡æ•°æ®ï¼‰
            "structured_summary": safe_dict(result_data.get("structured_summary"))
        }

        # ç‰¹åˆ«å¤„ç†reportså­—æ®µ - ç¡®ä¿æ¯ä¸ªæŠ¥å‘Šéƒ½æ˜¯æœ‰æ•ˆå­—ç¬¦ä¸²
        reports_data = safe_dict(result_data.get("reports"))
        validated_reports = {}

        for report_key, report_content in reports_data.items():
            # ç¡®ä¿æŠ¥å‘Šé”®æ˜¯å­—ç¬¦ä¸²
            safe_key = safe_string(report_key, "unknown_report")

            # ç¡®ä¿æŠ¥å‘Šå†…å®¹æ˜¯éç©ºå­—ç¬¦ä¸²
            if report_content is None:
                validated_content = "æŠ¥å‘Šå†…å®¹æš‚æ— "
            elif isinstance(report_content, str):
                validated_content = report_content.strip() if report_content.strip() else "æŠ¥å‘Šå†…å®¹ä¸ºç©º"
            else:
                validated_content = str(report_content).strip() if str(report_content).strip() else "æŠ¥å‘Šå†…å®¹æ ¼å¼é”™è¯¯"

            validated_reports[safe_key] = validated_content

        final_result_data["reports"] = validated_reports

        logger.info(f"âœ… [RESULT] æˆåŠŸè·å–ä»»åŠ¡ç»“æœ: {task_id}")
        logger.info(f"ğŸ“Š [RESULT] æœ€ç»ˆè¿”å› {len(final_result_data.get('reports', {}))} ä¸ªæŠ¥å‘Š")

        # ğŸ” è°ƒè¯•ï¼šæ£€æŸ¥æœ€ç»ˆè¿”å›çš„æ•°æ®
        logger.info(f"ğŸ” [FINAL] æœ€ç»ˆè¿”å›æ•°æ®é”®: {list(final_result_data.keys())}")
        logger.info(f"ğŸ” [FINAL] æœ€ç»ˆè¿”å›ä¸­æœ‰decision: {bool(final_result_data.get('decision'))}")
        if final_result_data.get('decision'):
            logger.info(f"ğŸ” [FINAL] æœ€ç»ˆdecisionå†…å®¹: {final_result_data['decision']}")

        return {
            "success": True,
            "data": final_result_data,
            "message": "åˆ†æç»“æœè·å–æˆåŠŸ"
        }

    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"âŒ [RESULT] è·å–ä»»åŠ¡ç»“æœå¤±è´¥: {e}")
        raise HTTPException(status_code=400, detail=str(e))

@router.get("/tasks/all", response_model=Dict[str, Any])
async def list_all_tasks(
    user: dict = Depends(get_current_user),
    status: Optional[str] = Query(None, description="ä»»åŠ¡çŠ¶æ€è¿‡æ»¤"),
    limit: int = Query(20, ge=1, le=100, description="è¿”å›æ•°é‡é™åˆ¶"),
    offset: int = Query(0, ge=0, description="åç§»é‡")
):
    """è·å–æ‰€æœ‰ä»»åŠ¡åˆ—è¡¨ï¼ˆä¸é™ç”¨æˆ·ï¼‰"""
    try:
        from app.services.analysis_service import get_analysis_service
        logger.info(f"ğŸ“‹ æŸ¥è¯¢æ‰€æœ‰ä»»åŠ¡åˆ—è¡¨")

        tasks = await get_analysis_service().list_all_tasks(
            status=status,
            limit=limit,
            offset=offset
        )

        return {
            "success": True,
            "data": {
                "tasks": tasks,
                "total": len(tasks),
                "limit": limit,
                "offset": offset
            },
            "message": "ä»»åŠ¡åˆ—è¡¨è·å–æˆåŠŸ"
        }

    except Exception as e:
        logger.error(f"âŒ è·å–ä»»åŠ¡åˆ—è¡¨å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@router.get("/tasks", response_model=Dict[str, Any])
async def list_user_tasks(
    user: dict = Depends(get_current_user),
    status: Optional[str] = Query(None, description="ä»»åŠ¡çŠ¶æ€è¿‡æ»¤"),
    limit: int = Query(20, ge=1, le=100, description="è¿”å›æ•°é‡é™åˆ¶"),
    offset: int = Query(0, ge=0, description="åç§»é‡")
):
    """è·å–ç”¨æˆ·çš„ä»»åŠ¡åˆ—è¡¨"""
    try:
        from app.services.analysis_service import get_analysis_service
        logger.info(f"ğŸ“‹ æŸ¥è¯¢ç”¨æˆ·ä»»åŠ¡åˆ—è¡¨: {user['id']}")

        tasks = await get_analysis_service().list_user_tasks(
            user_id=user["id"],
            status=status,
            limit=limit,
            offset=offset
        )

        return {
            "success": True,
            "data": {
                "tasks": tasks,
                "total": len(tasks),
                "limit": limit,
                "offset": offset
            },
            "message": "ä»»åŠ¡åˆ—è¡¨è·å–æˆåŠŸ"
        }

    except Exception as e:
        logger.error(f"âŒ è·å–ä»»åŠ¡åˆ—è¡¨å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@router.post("/batch", response_model=Dict[str, Any])
async def submit_batch_analysis(
    request: BatchAnalysisRequest,
    user: dict = Depends(get_current_user)
):
    """æäº¤æ‰¹é‡åˆ†æä»»åŠ¡ï¼ˆçœŸæ­£çš„å¹¶å‘æ‰§è¡Œï¼‰

    âš ï¸ æ³¨æ„ï¼šä¸ä½¿ç”¨ BackgroundTasksï¼Œå› ä¸ºå®ƒæ˜¯ä¸²è¡Œæ‰§è¡Œçš„ï¼
    æ”¹ç”¨ asyncio.create_task å®ç°çœŸæ­£çš„å¹¶å‘æ‰§è¡Œã€‚
    """
    try:
        logger.info(f"ğŸ¯ [æ‰¹é‡åˆ†æ] æ”¶åˆ°æ‰¹é‡åˆ†æè¯·æ±‚: title={request.title}")

        # å»¶è¿Ÿå¯¼å…¥ï¼Œé¿å…å¾ªç¯å¼•ç”¨
        from app.services.analysis_service import get_analysis_service
        simple_service = get_analysis_service()
        
        batch_id = str(uuid.uuid4())
        task_ids: List[str] = []
        mapping: List[Dict[str, str]] = []

        # è·å–è‚¡ç¥¨ä»£ç åˆ—è¡¨ (å…¼å®¹æ—§å­—æ®µ)
        stock_symbols = request.get_symbols()
        logger.info(f"ğŸ“Š [æ‰¹é‡åˆ†æ] è‚¡ç¥¨ä»£ç åˆ—è¡¨: {stock_symbols}")

        # éªŒè¯è‚¡ç¥¨ä»£ç åˆ—è¡¨
        if not stock_symbols:
            raise ValueError("è‚¡ç¥¨ä»£ç åˆ—è¡¨ä¸èƒ½ä¸ºç©º")

        # ğŸ”§ é™åˆ¶æ‰¹é‡åˆ†æçš„è‚¡ç¥¨æ•°é‡ï¼ˆæœ€å¤š10ä¸ªï¼‰
        MAX_BATCH_SIZE = 10
        if len(stock_symbols) > MAX_BATCH_SIZE:
            raise ValueError(f"æ‰¹é‡åˆ†ææœ€å¤šæ”¯æŒ {MAX_BATCH_SIZE} ä¸ªè‚¡ç¥¨ï¼Œå½“å‰æäº¤äº† {len(stock_symbols)} ä¸ª")

        # ä¸ºæ¯åªè‚¡ç¥¨åˆ›å»ºå•è‚¡åˆ†æä»»åŠ¡
        for i, symbol in enumerate(stock_symbols):
            logger.info(f"ğŸ“ [æ‰¹é‡åˆ†æ] æ­£åœ¨åˆ›å»ºç¬¬ {i+1}/{len(stock_symbols)} ä¸ªä»»åŠ¡: {symbol}")

            single_req = SingleAnalysisRequest(
                symbol=symbol,
                stock_code=symbol,  # å…¼å®¹å­—æ®µ
                parameters=request.parameters
            )

            try:
                create_res = await simple_service.create_analysis_task(user["id"], single_req)
                task_id = create_res.get("task_id")
                if not task_id:
                    raise RuntimeError(f"åˆ›å»ºä»»åŠ¡å¤±è´¥ï¼šæœªè¿”å›task_id (symbol={symbol})")
                task_ids.append(task_id)
                mapping.append({"symbol": symbol, "stock_code": symbol, "task_id": task_id})
                logger.info(f"âœ… [æ‰¹é‡åˆ†æ] å·²åˆ›å»ºä»»åŠ¡: {task_id} - {symbol}")
            except Exception as create_error:
                logger.error(f"âŒ [æ‰¹é‡åˆ†æ] åˆ›å»ºä»»åŠ¡å¤±è´¥: {symbol}, é”™è¯¯: {create_error}", exc_info=True)
                raise

        # ğŸ”§ ä½¿ç”¨ asyncio.create_task å®ç°çœŸæ­£çš„å¹¶å‘æ‰§è¡Œ
        # ä¸ä½¿ç”¨ BackgroundTasksï¼Œå› ä¸ºå®ƒæ˜¯ä¸²è¡Œæ‰§è¡Œçš„
        async def run_concurrent_analysis():
            """å¹¶å‘æ‰§è¡Œæ‰€æœ‰åˆ†æä»»åŠ¡"""
            # å»¶è¿Ÿå¯¼å…¥ï¼Œé¿å…å¾ªç¯å¼•ç”¨
            from app.services.analysis_service import get_analysis_service
            simple_service = get_analysis_service()
            
            tasks = []
            for i, symbol in enumerate(stock_symbols):
                task_id = task_ids[i]
                single_req = SingleAnalysisRequest(
                    symbol=symbol,
                    stock_code=symbol,
                    parameters=request.parameters
                )

                # åˆ›å»ºå¼‚æ­¥ä»»åŠ¡
                async def run_single_analysis(tid: str, req: SingleAnalysisRequest, uid: str):
                    try:
                        logger.info(f"ğŸš€ [å¹¶å‘ä»»åŠ¡] å¼€å§‹æ‰§è¡Œ: {tid} - {req.stock_code}")
                        await simple_service.execute_analysis_background(tid, uid, req)
                        logger.info(f"âœ… [å¹¶å‘ä»»åŠ¡] æ‰§è¡Œå®Œæˆ: {tid}")
                    except Exception as e:
                        logger.error(f"âŒ [å¹¶å‘ä»»åŠ¡] æ‰§è¡Œå¤±è´¥: {tid}, é”™è¯¯: {e}", exc_info=True)

                # æ·»åŠ åˆ°ä»»åŠ¡åˆ—è¡¨
                task = asyncio.create_task(run_single_analysis(task_id, single_req, user["id"]))
                tasks.append(task)
                logger.info(f"âœ… [æ‰¹é‡åˆ†æ] å·²åˆ›å»ºå¹¶å‘ä»»åŠ¡: {task_id} - {symbol}")

            # ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆï¼ˆä¸é˜»å¡å“åº”ï¼‰
            await asyncio.gather(*tasks, return_exceptions=True)
            logger.info(f"ğŸ‰ [æ‰¹é‡åˆ†æ] æ‰€æœ‰ä»»åŠ¡æ‰§è¡Œå®Œæˆ: batch_id={batch_id}")

        # åœ¨åå°å¯åŠ¨å¹¶å‘ä»»åŠ¡ï¼ˆä¸ç­‰å¾…å®Œæˆï¼‰
        asyncio.create_task(run_concurrent_analysis())
        logger.info(f"ğŸš€ [æ‰¹é‡åˆ†æ] å·²å¯åŠ¨ {len(task_ids)} ä¸ªå¹¶å‘ä»»åŠ¡")

        return {
            "success": True,
            "data": {
                "batch_id": batch_id,
                "total_tasks": len(task_ids),
                "task_ids": task_ids,
                "mapping": mapping,
                "status": "submitted"
            },
            "message": f"æ‰¹é‡åˆ†æä»»åŠ¡å·²æäº¤ï¼Œå…±{len(task_ids)}ä¸ªè‚¡ç¥¨ï¼Œæ­£åœ¨å¹¶å‘æ‰§è¡Œ"
        }
    except Exception as e:
        logger.error(f"âŒ [æ‰¹é‡åˆ†æ] æäº¤å¤±è´¥: {e}", exc_info=True)
        raise HTTPException(status_code=400, detail=str(e))

# å…¼å®¹æ€§ï¼šä¿ç•™åŸæœ‰ç«¯ç‚¹
@router.post("/analyze")
async def analyze_single(
    req: SingleAnalyzeRequest,
    user: dict = Depends(get_current_user),
    svc: QueueService = Depends(get_queue_service)
):
    """å•è‚¡åˆ†æï¼ˆå…¼å®¹æ€§ç«¯ç‚¹ï¼‰"""
    try:
        task_id = await svc.enqueue_task(
            user_id=user["id"],
            symbol=req.symbol,
            params=req.parameters
        )
        return {"task_id": task_id, "status": "queued"}
    except Exception as e:
        raise HTTPException(status_code=400, detail=str(e))

@router.post("/analyze/batch")
async def analyze_batch(
    req: BatchAnalyzeRequest,
    user: dict = Depends(get_current_user),
    svc: QueueService = Depends(get_queue_service)
):
    """æ‰¹é‡åˆ†æï¼ˆå…¼å®¹æ€§ç«¯ç‚¹ï¼‰"""
    try:
        batch_id, submitted = await svc.create_batch(
            user_id=user["id"],
            symbols=req.symbols,
            params=req.parameters
        )
        return {"batch_id": batch_id, "submitted": submitted}
    except Exception as e:
        raise HTTPException(status_code=400, detail=str(e))

@router.get("/batches/{batch_id}")
async def get_batch(batch_id: str, user: dict = Depends(get_current_user), svc: QueueService = Depends(get_queue_service)):
    b = await svc.get_batch(batch_id)
    if not b or b.get("user") != user["id"]:
        raise HTTPException(status_code=404, detail="batch not found")
    return b

# ä»»åŠ¡å’Œæ‰¹æ¬¡æŸ¥è¯¢ç«¯ç‚¹
# æ³¨æ„ï¼šè¿™ä¸ªè·¯ç”±è¢«ç§»åˆ°äº† /tasks/{task_id}/status ä¹‹åï¼Œé¿å…è·¯ç”±å†²çª
# @router.get("/tasks/{task_id}")
# async def get_task(
#     task_id: str,
#     user: dict = Depends(get_current_user),
#     svc: QueueService = Depends(get_queue_service)
# ):
#     """è·å–ä»»åŠ¡è¯¦æƒ…"""
#     t = await svc.get_task(task_id)
#     if not t or t.get("user") != user["id"]:
#         raise HTTPException(status_code=404, detail="ä»»åŠ¡ä¸å­˜åœ¨")
#     return t

# åŸæœ‰çš„è·¯ç”±å·²è¢«æ–°çš„å¼‚æ­¥å®ç°æ›¿ä»£
# @router.get("/tasks/{task_id}/status")
# async def get_task_status_old(
#     task_id: str,
#     user: dict = Depends(get_current_user)
# ):
#     """è·å–ä»»åŠ¡çŠ¶æ€å’Œè¿›åº¦ï¼ˆæ—§ç‰ˆå®ç°ï¼‰"""
#     try:
#         status = await get_analysis_service().get_task_status(task_id)
#         if not status:
#             raise HTTPException(status_code=404, detail="ä»»åŠ¡ä¸å­˜åœ¨")
#         return {
#             "success": True,
#             "data": status
#         }
#     except Exception as e:
#         raise HTTPException(status_code=400, detail=str(e))

@router.post("/tasks/{task_id}/cancel")
async def cancel_task(
    task_id: str,
    user: dict = Depends(get_current_user),
    svc: QueueService = Depends(get_queue_service)
):
    """å–æ¶ˆä»»åŠ¡"""
    try:
        # éªŒè¯ä»»åŠ¡æ‰€æœ‰æƒ
        task = await svc.get_task(task_id)
        if not task or task.get("user") != user["id"]:
            raise HTTPException(status_code=404, detail="ä»»åŠ¡ä¸å­˜åœ¨")

        success = await svc.cancel_task(task_id)
        if success:
            return {"success": True, "message": "ä»»åŠ¡å·²å–æ¶ˆ"}
        else:
            raise HTTPException(status_code=400, detail="å–æ¶ˆä»»åŠ¡å¤±è´¥")
    except Exception as e:
        raise HTTPException(status_code=400, detail=str(e))

@router.get("/user/queue-status")
async def get_user_queue_status(
    user: dict = Depends(get_current_user),
    svc: QueueService = Depends(get_queue_service)
):
    """è·å–ç”¨æˆ·é˜Ÿåˆ—çŠ¶æ€"""
    try:
        status = await svc.get_user_queue_status(user["id"])
        return {
            "success": True,
            "data": status
        }
    except Exception as e:
        raise HTTPException(status_code=400, detail=str(e))

@router.get("/user/history")
async def get_user_analysis_history(
    user: dict = Depends(get_current_user),
    status: Optional[str] = Query(None, description="ä»»åŠ¡çŠ¶æ€è¿‡æ»¤"),
    start_date: Optional[str] = Query(None, description="å¼€å§‹æ—¥æœŸï¼ŒYYYY-MM-DD"),
    end_date: Optional[str] = Query(None, description="ç»“æŸæ—¥æœŸï¼ŒYYYY-MM-DD"),
    symbol: Optional[str] = Query(None, description="è‚¡ç¥¨ä»£ç "),
    stock_code: Optional[str] = Query(None, description="è‚¡ç¥¨ä»£ç (å·²åºŸå¼ƒ,ä½¿ç”¨symbol)"),
    market_type: Optional[str] = Query(None, description="å¸‚åœºç±»å‹"),
    page: int = Query(1, ge=1, description="é¡µç "),
    page_size: int = Query(20, ge=1, le=100, description="æ¯é¡µå¤§å°")
):
    """è·å–ç”¨æˆ·åˆ†æå†å²ï¼ˆæ”¯æŒåŸºç¡€ç­›é€‰ä¸åˆ†é¡µï¼‰"""
    try:
        from app.services.analysis_service import get_analysis_service
        query_symbol = symbol or stock_code

        # ä½¿ç”¨æ–°çš„ query_user_tasks æ–¹æ³•ï¼Œæ”¯æŒæ•°æ®åº“å±‚é¢çš„ç­›é€‰å’Œåˆ†é¡µ
        result = await get_analysis_service().query_user_tasks(
            user_id=user["id"],
            status=status,
            start_date=start_date,
            end_date=end_date,
            symbol=query_symbol,
            market_type=market_type,
            page=page,
            page_size=page_size
        )

        return {
            "success": True,
            "data": result,
            "message": "å†å²æŸ¥è¯¢æˆåŠŸ"
        }
    except Exception as e:
        logger.error(f"âŒ è·å–ç”¨æˆ·åˆ†æå†å²å¤±è´¥: {e}")
        raise HTTPException(status_code=400, detail=str(e))

# WebSocket ç«¯ç‚¹
@router.websocket("/ws/task/{task_id}")
async def websocket_task_progress(websocket: WebSocket, task_id: str):
    """WebSocket ç«¯ç‚¹ï¼šå®æ—¶è·å–ä»»åŠ¡è¿›åº¦"""
    import json
    websocket_manager = get_websocket_manager()

    try:
        # âš ï¸ å…³é”®ä¿®å¤ï¼š
        # 1. websocket_manager.connect å†…éƒ¨ä¼šè°ƒç”¨ websocket.accept()
        # 2. 403 é”™è¯¯é€šå¸¸æ˜¯å› ä¸ºæ²¡æœ‰åŠæ—¶ acceptï¼Œæˆ–è€…ä¸­é—´ä»¶æ‹¦æˆª
        # 3. è¿™é‡Œæˆ‘ä»¬ç›´æ¥è°ƒç”¨ connectï¼Œè®©å®ƒå¤„ç†æ¡æ‰‹
        logger.info(f"ğŸ”Œ [WS] å°è¯•å»ºç«‹è¿æ¥: task_id={task_id}")
        
        # æ³¨æ„ï¼šå¦‚æœ websocket_manager.connect å†…éƒ¨æŠ›å‡ºå¼‚å¸¸ï¼Œè¿æ¥ä¼šå¤±è´¥
        # æˆ‘ä»¬éœ€è¦ç¡®ä¿åœ¨ connect ä¹‹å‰æ²¡æœ‰å…¶ä»–æ“ä½œé˜»å¡
        await websocket_manager.connect(websocket, task_id)

        # å‘é€è¿æ¥ç¡®è®¤æ¶ˆæ¯
        await websocket.send_text(json.dumps({
            "type": "connection_established",
            "task_id": task_id,
            "message": "WebSocket è¿æ¥å·²å»ºç«‹"
        }))

        # ä¿æŒè¿æ¥æ´»è·ƒ
        while True:
            try:
                # æ¥æ”¶å®¢æˆ·ç«¯çš„å¿ƒè·³æ¶ˆæ¯
                data = await websocket.receive_text()
                # å¯ä»¥å¤„ç†å®¢æˆ·ç«¯å‘é€çš„æ¶ˆæ¯
                logger.debug(f"ğŸ“¡ æ”¶åˆ° WebSocket æ¶ˆæ¯: {data}")
            except WebSocketDisconnect:
                break
            except Exception as e:
                logger.warning(f"âš ï¸ WebSocket æ¶ˆæ¯å¤„ç†é”™è¯¯: {e}")
                break

    except WebSocketDisconnect:
        logger.info(f"ğŸ”Œ WebSocket å®¢æˆ·ç«¯æ–­å¼€è¿æ¥: {task_id}")
    except Exception as e:
        logger.error(f"âŒ WebSocket è¿æ¥é”™è¯¯: {e}")
    finally:
        await websocket_manager.disconnect(websocket, task_id)

# ä»»åŠ¡è¯¦æƒ…æŸ¥è¯¢è·¯ç”±ï¼ˆæ”¾åœ¨æœ€åé¿å…ä¸ /tasks/{task_id}/status å†²çªï¼‰
@router.get("/tasks/{task_id}/details")
async def get_task_details(
    task_id: str,
    user: dict = Depends(get_current_user),
    svc: QueueService = Depends(get_queue_service)
):
    """è·å–ä»»åŠ¡è¯¦æƒ…ï¼ˆä½¿ç”¨ä¸åŒçš„è·¯å¾„é¿å…å†²çªï¼‰"""
    t = await svc.get_task(task_id)
    if not t or t.get("user") != user["id"]:
        raise HTTPException(status_code=404, detail="ä»»åŠ¡ä¸å­˜åœ¨")
    return t


# ==================== åƒµå°¸ä»»åŠ¡ç®¡ç† ====================

@router.get("/admin/zombie-tasks")
async def get_zombie_tasks(
    max_running_hours: int = Query(default=2, ge=1, le=72, description="æœ€å¤§è¿è¡Œæ—¶é•¿ï¼ˆå°æ—¶ï¼‰"),
    user: dict = Depends(get_current_user)
):
    """è·å–åƒµå°¸ä»»åŠ¡åˆ—è¡¨ï¼ˆä»…ç®¡ç†å‘˜ï¼‰

    åƒµå°¸ä»»åŠ¡ï¼šé•¿æ—¶é—´å¤„äº processing/running/pending çŠ¶æ€çš„ä»»åŠ¡
    """
    # æ£€æŸ¥ç®¡ç†å‘˜æƒé™
    if user.get("username") != "admin":
        raise HTTPException(status_code=403, detail="ä»…ç®¡ç†å‘˜å¯è®¿é—®")

    try:
        from app.services.analysis_service import get_analysis_service
        svc = get_analysis_service()
        zombie_tasks = await svc.get_zombie_tasks(max_running_hours)

        return {
            "success": True,
            "data": zombie_tasks,
            "total": len(zombie_tasks),
            "max_running_hours": max_running_hours
        }
    except Exception as e:
        logger.error(f"âŒ è·å–åƒµå°¸ä»»åŠ¡å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"è·å–åƒµå°¸ä»»åŠ¡å¤±è´¥: {str(e)}")


@router.post("/admin/cleanup-zombie-tasks")
async def cleanup_zombie_tasks(
    max_running_hours: int = Query(default=2, ge=1, le=72, description="æœ€å¤§è¿è¡Œæ—¶é•¿ï¼ˆå°æ—¶ï¼‰"),
    user: dict = Depends(get_current_user)
):
    """æ¸…ç†åƒµå°¸ä»»åŠ¡ï¼ˆä»…ç®¡ç†å‘˜ï¼‰

    å°†é•¿æ—¶é—´å¤„äº processing/running/pending çŠ¶æ€çš„ä»»åŠ¡æ ‡è®°ä¸ºå¤±è´¥
    """
    # æ£€æŸ¥ç®¡ç†å‘˜æƒé™
    if user.get("username") != "admin":
        raise HTTPException(status_code=403, detail="ä»…ç®¡ç†å‘˜å¯è®¿é—®")

    try:
        from app.services.analysis_service import get_analysis_service
        svc = get_analysis_service()
        result = await svc.cleanup_zombie_tasks(max_running_hours)

        return {
            "success": True,
            "data": result,
            "message": f"å·²æ¸…ç† {result.get('total_cleaned', 0)} ä¸ªåƒµå°¸ä»»åŠ¡"
        }
    except Exception as e:
        logger.error(f"âŒ æ¸…ç†åƒµå°¸ä»»åŠ¡å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"æ¸…ç†åƒµå°¸ä»»åŠ¡å¤±è´¥: {str(e)}")


@router.post("/tasks/{task_id}/mark-failed")
async def mark_task_as_failed(
    task_id: str,
    user: dict = Depends(get_current_user)
):
    """å°†æŒ‡å®šä»»åŠ¡æ ‡è®°ä¸ºå¤±è´¥

    ç”¨äºæ‰‹åŠ¨æ¸…ç†å¡ä½çš„ä»»åŠ¡
    """
    try:
        from app.services.analysis_service import get_analysis_service
        svc = get_analysis_service()

        # æ›´æ–°å†…å­˜ä¸­çš„ä»»åŠ¡çŠ¶æ€
        from app.services.memory_state_manager import TaskStatus
        await svc.memory_manager.update_task_status(
            task_id=task_id,
            status=TaskStatus.FAILED,
            message="æ‰‹åŠ¨æ ‡è®°ä¸ºå¤±è´¥",
            error_message="ç”¨æˆ·æ‰‹åŠ¨æ ‡è®°ä¸ºå¤±è´¥"
        )

        # æ›´æ–° MongoDB ä¸­çš„ä»»åŠ¡çŠ¶æ€
        from app.core.database import get_mongo_db
        from datetime import datetime
        db = get_mongo_db()

        result = await db.analysis_tasks.update_one(
            {"task_id": task_id},
            {
                "$set": {
                    "status": "failed",
                    "last_error": "ç”¨æˆ·æ‰‹åŠ¨æ ‡è®°ä¸ºå¤±è´¥",
                    "completed_at": now_utc(),
                    "updated_at": now_utc()
                }
            }
        )

        if result.modified_count > 0:
            logger.info(f"âœ… ä»»åŠ¡ {task_id} å·²æ ‡è®°ä¸ºå¤±è´¥")
            return {
                "success": True,
                "message": "ä»»åŠ¡å·²æ ‡è®°ä¸ºå¤±è´¥"
            }
        else:
            logger.warning(f"âš ï¸ ä»»åŠ¡ {task_id} æœªæ‰¾åˆ°æˆ–å·²æ˜¯å¤±è´¥çŠ¶æ€")
            return {
                "success": True,
                "message": "ä»»åŠ¡æœªæ‰¾åˆ°æˆ–å·²æ˜¯å¤±è´¥çŠ¶æ€"
            }
    except Exception as e:
        logger.error(f"âŒ æ ‡è®°ä»»åŠ¡å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"æ ‡è®°ä»»åŠ¡å¤±è´¥: {str(e)}")


@router.delete("/tasks/{task_id}")
async def delete_task(
    task_id: str,
    user: dict = Depends(get_current_user)
):
    """åˆ é™¤æŒ‡å®šä»»åŠ¡

    ä»å†…å­˜å’Œæ•°æ®åº“ä¸­åˆ é™¤ä»»åŠ¡è®°å½•
    """
    try:
        from app.services.analysis_service import get_analysis_service
        svc = get_analysis_service()

        # ä»å†…å­˜ä¸­åˆ é™¤ä»»åŠ¡
        await svc.memory_manager.remove_task(task_id)

        # ä» MongoDB ä¸­åˆ é™¤ä»»åŠ¡
        from app.core.database import get_mongo_db
        db = get_mongo_db()

        result = await db.analysis_tasks.delete_one({"task_id": task_id})

        if result.deleted_count > 0:
            logger.info(f"âœ… ä»»åŠ¡ {task_id} å·²åˆ é™¤")
            return {
                "success": True,
                "message": "ä»»åŠ¡å·²åˆ é™¤"
            }
        else:
            logger.warning(f"âš ï¸ ä»»åŠ¡ {task_id} æœªæ‰¾åˆ°")
            return {
                "success": True,
                "message": "ä»»åŠ¡æœªæ‰¾åˆ°"
            }
    except Exception as e:
        logger.error(f"âŒ åˆ é™¤ä»»åŠ¡å¤±è´¥: {e}")
        raise HTTPException(status_code=500, detail=f"åˆ é™¤ä»»åŠ¡å¤±è´¥: {str(e)}")