"""
MCP æƒ…ç»ªåˆ†æå·¥å…·

ä½¿ç”¨ FastMCP çš„ @mcp.tool() è£…é¥°å™¨å®šä¹‰ç»Ÿä¸€æƒ…ç»ªåˆ†æå·¥å…·ã€‚
ä¿ç•™ç°æœ‰çš„ç¤¾äº¤åª’ä½“æƒ…ç»ªåˆ†æé€»è¾‘ï¼Œæ”¯æŒ Aè‚¡ã€æ¸¯è‚¡ã€ç¾è‚¡ã€‚
"""

import logging
from datetime import datetime
from typing import Optional

logger = logging.getLogger(__name__)

# å…¨å±€ toolkit é…ç½®
_toolkit_config: dict = {}


def set_toolkit_config(config: dict):
    """è®¾ç½®å·¥å…·é…ç½®"""
    global _toolkit_config
    _toolkit_config = config or {}


def get_stock_sentiment(
    ticker: str,
    curr_date: str,
    start_date: Optional[str] = None,
    end_date: Optional[str] = None,
    source_name: Optional[str] = None
) -> str:
    """
    ç»Ÿä¸€è‚¡ç¥¨æƒ…ç»ªåˆ†æå·¥å…· - è·å–å¸‚åœºå¯¹è‚¡ç¥¨çš„æƒ…ç»ªå€¾å‘ã€‚
    
    è‡ªåŠ¨è¯†åˆ«è‚¡ç¥¨ç±»å‹å¹¶è°ƒç”¨ç›¸åº”æ•°æ®æºï¼ˆå¦‚ä¸­å›½ç¤¾äº¤åª’ä½“ã€Redditã€å†…éƒ¨äº¤æ˜“ç­‰ï¼‰ã€‚
    è¿”å›æ•°æ®åŒ…æ‹¬ï¼šæŠ•èµ„è€…æƒ…ç»ªæŒ‡æ•°ã€ç¤¾äº¤åª’ä½“çƒ­åº¦ã€å†…éƒ¨äººå£«äº¤æ˜“ä¿¡å·ç­‰ã€‚
    
    Args:
        ticker: è‚¡ç¥¨ä»£ç ï¼Œæ”¯æŒå¤šç§æ ¼å¼ï¼š
            - Aè‚¡ï¼šå¦‚ '600519', '000001', '300750'
            - æ¸¯è‚¡ï¼šå¦‚ '0700.HK', '09988'
            - ç¾è‚¡ï¼šå¦‚ 'AAPL', 'TSLA', 'NVDA'
        curr_date: å½“å‰æ—¥æœŸï¼Œæ ¼å¼ï¼šYYYY-MM-DD
        start_date: å¯é€‰ï¼šå¼€å§‹æ—¥æœŸ (YYYY-MM-DD)ï¼Œå¦‚æœä¸æä¾›åˆ™é»˜è®¤åˆ†æcurr_dateå½“å¤©
        end_date: å¯é€‰ï¼šç»“æŸæ—¥æœŸ (YYYY-MM-DD)ï¼Œå¦‚æœä¸æä¾›åˆ™é»˜è®¤åˆ†æcurr_dateå½“å¤©
        source_name: å¯é€‰ï¼šæŒ‡å®šæ•°æ®æºåç§°ï¼ˆå¦‚'é›ªçƒ'ã€'Reddit'ï¼‰ï¼Œå¦‚æœä¸æ”¯æŒå°†è‡ªåŠ¨å¿½ç•¥
    
    Returns:
        æ ¼å¼åŒ–çš„æƒ…ç»ªåˆ†ææ•°æ®ï¼ŒåŒ…å«æƒ…ç»ªæŒ‡æ•°å’Œç¤¾äº¤åª’ä½“çƒ­åº¦
    """
    logger.info(f"ğŸ˜Š [MCPæƒ…ç»ªå·¥å…·] åˆ†æè‚¡ç¥¨: {ticker}")
    start_time = datetime.now()

    try:
        from tradingagents.utils.stock_utils import StockUtils

        # è‡ªåŠ¨è¯†åˆ«è‚¡ç¥¨ç±»å‹
        market_info = StockUtils.get_market_info(ticker)
        is_china = market_info['is_china']
        is_hk = market_info['is_hk']
        is_us = market_info['is_us']

        logger.info(f"ğŸ˜Š [MCPæƒ…ç»ªå·¥å…·] è‚¡ç¥¨ç±»å‹: {market_info['market_name']}")

        result_data = []

        if is_china or is_hk:
            # ä¸­å›½Aè‚¡å’Œæ¸¯è‚¡ï¼šä½¿ç”¨ç¤¾äº¤åª’ä½“æƒ…ç»ªåˆ†æ
            logger.info(f"ğŸ‡¨ğŸ‡³ğŸ‡­ğŸ‡° [MCPæƒ…ç»ªå·¥å…·] å¤„ç†ä¸­æ–‡å¸‚åœºæƒ…ç»ª...")

            try:
                from tradingagents.dataflows.interface import get_chinese_social_sentiment
                sentiment_data = get_chinese_social_sentiment(ticker, curr_date)
                
                if sentiment_data and len(sentiment_data) > 50:
                    result_data.append(f"## ä¸­æ–‡ç¤¾äº¤åª’ä½“æƒ…ç»ª\n{sentiment_data}")
                    logger.info(f"âœ… [MCPæƒ…ç»ªå·¥å…·] ä¸­æ–‡æƒ…ç»ªæ•°æ®è·å–æˆåŠŸ")
                else:
                    logger.warning(f"âš ï¸ [MCPæƒ…ç»ªå·¥å…·] ä¸­æ–‡æƒ…ç»ªæ•°æ®ä¸ºç©ºæˆ–è¿‡çŸ­ï¼Œå°è¯•å¤‡ç”¨æº")
                    # å¤‡ç”¨ï¼šRedditæ–°é—» (éœ€è¦å¤„ç†è·¯å¾„é—®é¢˜å’Œå¯¼å…¥)
                    try:
                        # ç¡®ä¿è·¯å¾„å­˜åœ¨
                        import os
                        from tradingagents.config.config_manager import config_manager
                        data_dir = config_manager.get_data_dir()
                        reddit_path = os.path.join(data_dir, "reddit_data", "company_news")
                        os.makedirs(reddit_path, exist_ok=True)
                        
                        try:
                            from tradingagents.dataflows.interface import get_reddit_company_news
                        except ImportError:
                            # å°è¯•ç›´æ¥å¯¼å…¥
                            from tradingagents.dataflows.news.reddit import get_company_news as get_reddit_company_news
                            
                        reddit_data = get_reddit_company_news(ticker, curr_date, 7, 5)
                        result_data.append(f"## Redditè®¨è®º(å¤‡ç”¨)\n{reddit_data}")
                    except Exception as e:
                        result_data.append(f"## ç¤¾äº¤åª’ä½“æƒ…ç»ª\nâš ï¸ æ•°æ®è·å–å¤±è´¥: {e}")

            except Exception as e:
                logger.error(f"âŒ [MCPæƒ…ç»ªå·¥å…·] ä¸­æ–‡æƒ…ç»ªè·å–å¤±è´¥: {e}")
                result_data.append(f"## å¸‚åœºæƒ…ç»ªåˆ†æ\næš‚æ— æ•°æ® (æ•°æ®æºè®¿é—®å¼‚å¸¸)")

        else:
            # ç¾è‚¡ï¼šä½¿ç”¨Finnhubå†…å¹•äº¤æ˜“å’Œæƒ…ç»ªæ•°æ®
            logger.info(f"ğŸ‡ºğŸ‡¸ [MCPæƒ…ç»ªå·¥å…·] å¤„ç†ç¾è‚¡å¸‚åœºæƒ…ç»ª...")

            try:
                # å°è¯•è·å–å†…å¹•äº¤æ˜“æƒ…ç»ª
                try:
                    try:
                        from tradingagents.dataflows.interface import get_finnhub_company_insider_sentiment
                    except ImportError:
                        # å¦‚æœinterfaceæ²¡æœ‰å¯¼å‡ºï¼Œå¯èƒ½æ˜¯åå­—ä¸åŒ¹é…ï¼Œå°è¯•ç›´æ¥å¯¼å…¥æˆ–ä½¿ç”¨åˆ«å
                        from tradingagents.dataflows.interface import get_finnhub_company_insider_sentiment
                    
                    insider_sentiment = get_finnhub_company_insider_sentiment(ticker, curr_date, 30)
                    if insider_sentiment:
                        result_data.append(f"## å†…éƒ¨äººå£«æƒ…ç»ª\n{insider_sentiment}")
                except Exception as e:
                    logger.warning(f"âš ï¸ [MCPæƒ…ç»ªå·¥å…·] å†…å¹•äº¤æ˜“æ•°æ®è·å–å¤±è´¥: {e}")
                
                # å°è¯•è·å–Redditè®¨è®º
                try:
                    # ç¡®ä¿è·¯å¾„å­˜åœ¨
                    import os
                    from tradingagents.config.config_manager import config_manager
                    data_dir = config_manager.get_data_dir()
                    reddit_path = os.path.join(data_dir, "reddit_data", "company_news")
                    os.makedirs(reddit_path, exist_ok=True)

                    try:
                        from tradingagents.dataflows.interface import get_reddit_company_news
                    except ImportError:
                        from tradingagents.dataflows.news.reddit import get_company_news as get_reddit_company_news

                    reddit_info = get_reddit_company_news(ticker, curr_date, 7, 5)
                    if reddit_info:
                        result_data.append(f"## Redditè®¨è®º\n{reddit_info}")
                except Exception as e:
                    logger.warning(f"âš ï¸ [MCPæƒ…ç»ªå·¥å…·] Redditæ•°æ®è·å–å¤±è´¥: {e}")

                if not result_data:
                    result_data.append("## å¸‚åœºæƒ…ç»ªåˆ†æ\næš‚æ— æ•°æ®")

            except Exception as e:
                logger.error(f"âŒ [MCPæƒ…ç»ªå·¥å…·] ç¾è‚¡æƒ…ç»ªè·å–å¤±è´¥: {e}")
                result_data.append(f"## å¸‚åœºæƒ…ç»ªåˆ†æ\næš‚æ— æ•°æ® (æ•°æ®æºè®¿é—®å¼‚å¸¸)")

        # è®¡ç®—æ‰§è¡Œæ—¶é—´
        execution_time = (datetime.now() - start_time).total_seconds()

        # ç»„åˆæ‰€æœ‰æ•°æ®
        combined_result = f"""# {ticker} å¸‚åœºæƒ…ç»ªåˆ†æ

**è‚¡ç¥¨ç±»å‹**: {market_info['market_name']}
**åˆ†ææ—¥æœŸ**: {curr_date}
**æ‰§è¡Œæ—¶é—´**: {execution_time:.2f}ç§’

{chr(10).join(result_data)}

---
*æ•°æ®æ¥æº: ç¤¾äº¤åª’ä½“ã€æ–°é—»è¯„è®ºåŠå†…éƒ¨äº¤æ˜“æ•°æ®*
"""
        
        logger.info(f"ğŸ˜Š [MCPæƒ…ç»ªå·¥å…·] æ•°æ®è·å–å®Œæˆï¼Œæ€»é•¿åº¦: {len(combined_result)}")
        return combined_result

    except Exception as e:
        error_msg = f"âŒ ç»Ÿä¸€æƒ…ç»ªåˆ†æå·¥å…·æ‰§è¡Œå¤±è´¥: {str(e)}"
        logger.error(f"[MCPæƒ…ç»ªå·¥å…·] {error_msg}")
        return f"""# {ticker} å¸‚åœºæƒ…ç»ªåˆ†æ

âš ï¸ **é”™è¯¯**: {error_msg}

**å»ºè®®**:
- æ£€æŸ¥è‚¡ç¥¨ä»£ç æ˜¯å¦æ­£ç¡®
- ç¨åé‡è¯•æˆ–å°è¯•å…¶ä»–å·¥å…·
"""
