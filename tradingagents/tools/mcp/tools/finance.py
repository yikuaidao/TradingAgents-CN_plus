"""
MCP Finance Tools

Implements the 17 finance tools defined in FinanceMCP_Tools_Reference.md.

å¹¶å‘å®‰å…¨ï¼šä½¿ç”¨çº¿ç¨‹æœ¬åœ°å­˜å‚¨ï¼Œæ¯ä¸ªçº¿ç¨‹æœ‰ç‹¬ç«‹çš„ DataSourceManager å®ä¾‹
"""
import logging
import json
import re
import threading
from typing import Optional, Dict, Any, List
from datetime import datetime, timedelta
from tradingagents.dataflows.manager import DataSourceManager
from tradingagents.utils.time_utils import now_utc, get_current_date, get_current_date_compact
from .tool_standard import success_result, no_data_result, error_result, format_tool_result, ErrorCodes

logger = logging.getLogger(__name__)

# çº¿ç¨‹æœ¬åœ°å­˜å‚¨ï¼Œæ¯ä¸ªçº¿ç¨‹æœ‰ç‹¬ç«‹çš„ manager å®ä¾‹
_thread_local = threading.local()

def get_manager() -> DataSourceManager:
    """è·å–å½“å‰çº¿ç¨‹çš„ DataSourceManager å®ä¾‹ï¼ˆçº¿ç¨‹å®‰å…¨ï¼‰"""
    if not hasattr(_thread_local, 'manager'):
        _thread_local.manager = DataSourceManager()
        logger.debug(f"åˆ›å»ºæ–°çš„ DataSourceManager å®ä¾‹ (çº¿ç¨‹: {threading.current_thread().name})")
    return _thread_local.manager

# å‘åå…¼å®¹çš„å…¨å±€å¼•ç”¨ï¼ˆå®é™…ä¸Šè°ƒç”¨çº¿ç¨‹å®‰å…¨ç‰ˆæœ¬ï¼‰
def _get_global_manager():
    """å‘åå…¼å®¹ï¼šè·å–å…¨å±€ managerï¼ˆå·²åºŸå¼ƒï¼Œå»ºè®®ä½¿ç”¨ get_manager()ï¼‰"""
    return get_manager()

# --- 1. Stock Data ---

def get_stock_data(
    stock_code: str,
    market_type: str = "cn",
    start_date: Optional[str] = None,
    end_date: Optional[str] = None,
    indicators: Optional[str] = None
) -> str:
    """
    è·å–è‚¡ç¥¨è¡Œæƒ…æ•°æ®åŠæŠ€æœ¯æŒ‡æ ‡ã€‚

    è¿”å›å¼€ç›˜ä»·ã€æœ€é«˜ä»·ã€æœ€ä½ä»·ã€æ”¶ç›˜ä»·ã€æˆäº¤é‡ç­‰è¡Œæƒ…æ•°æ®ï¼Œä»¥åŠå¯é€‰çš„æŠ€æœ¯æŒ‡æ ‡ã€‚

    Args:
        stock_code: è‚¡ç¥¨ä»£ç ï¼Œå¦‚ "000001.SZ"(Aè‚¡)ã€"AAPL"(ç¾è‚¡)ã€"00700.HK"(æ¸¯è‚¡)
        market_type: å¸‚åœºç±»å‹: "cn"(Aè‚¡)ã€"us"(ç¾è‚¡)ã€"hk"(æ¸¯è‚¡)ï¼Œé»˜è®¤è‡ªåŠ¨æ¨æ–­
        start_date: å¼€å§‹æ—¥æœŸï¼Œæ ¼å¼ YYYY-MM-DD æˆ– YYYYMMDDï¼Œé»˜è®¤ 1 ä¸ªæœˆå‰
        end_date: ç»“æŸæ—¥æœŸï¼Œæ ¼å¼ YYYY-MM-DD æˆ– YYYYMMDDï¼Œé»˜è®¤ä»Šå¤©
        indicators: æŠ€æœ¯æŒ‡æ ‡è¡¨è¾¾å¼ï¼Œå¦‚ "macd(12,26,9) rsi(14)"

    Returns:
        JSON æ ¼å¼çš„ ToolResultï¼ŒåŒ…å« statusã€dataã€error_codeã€suggestion å­—æ®µ
    """
    try:
        from tradingagents.utils.stock_utils import StockUtils

        # 1. è‡ªåŠ¨æ¨æ–­å¸‚åœºç±»å‹ (ä¼˜å…ˆä½¿ç”¨ StockUtils)
        market_info = StockUtils.get_market_info(stock_code)
        is_china = market_info['is_china']
        is_hk = market_info['is_hk']
        is_us = market_info['is_us']

        # å¦‚æœæ— æ³•è¯†åˆ«ï¼Œå›é€€åˆ°å‚æ•°æŒ‡å®š
        if not (is_china or is_hk or is_us):
            if market_type == "hk": is_hk = True
            elif market_type == "us": is_us = True
            else: is_china = True

        # 2. è®¾ç½®é»˜è®¤æ—¥æœŸ
        if not start_date:
            start_date = (now_utc() - timedelta(days=30)).strftime('%Y-%m-%d')
        if not end_date:
            end_date = get_current_date()

        # 3. è°ƒç”¨ç»Ÿä¸€æ•°æ®æ¥å£ (åŒ…å« Write-Through é€»è¾‘)
        if is_china:
            from tradingagents.dataflows.interface import get_china_stock_data_unified
            data = get_china_stock_data_unified(stock_code, start_date, end_date)
            # ç›´æ¥è¿”å›åŸå§‹æ•°æ®ï¼Œä¸è½¬æ¢æ ¼å¼
            return f"## Aè‚¡è¡Œæƒ…æ•°æ® ({stock_code})\n{data}"

        elif is_hk:
            from tradingagents.dataflows.interface import get_hk_stock_data_unified
            data = get_hk_stock_data_unified(stock_code, start_date, end_date)
            # ç›´æ¥è¿”å›åŸå§‹æ•°æ®ï¼Œä¸è½¬æ¢æ ¼å¼
            return f"## æ¸¯è‚¡è¡Œæƒ…æ•°æ® ({stock_code})\n{data}"

        elif is_us:
            data = get_manager().get_stock_data(stock_code, "us", start_date, end_date)
            # ç›´æ¥è¿”å›åŸå§‹æ•°æ®ï¼Œä¸è½¬æ¢æ ¼å¼
            return f"## ç¾è‚¡è¡Œæƒ…æ•°æ® ({stock_code})\n{data}"

        # é”™è¯¯æƒ…å†µä¹Ÿè¿”å›åŸå§‹æ ¼å¼
        return f"âŒ é”™è¯¯ï¼šæ— æ³•è¯†åˆ«è‚¡ç¥¨ä»£ç  {stock_code} çš„å¸‚åœºç±»å‹"

    except Exception as e:
        logger.error(f"get_stock_data failed: {e}")
        # ç›´æ¥è¿”å›é”™è¯¯ä¿¡æ¯ï¼Œä¸è½¬æ¢ä¸º JSON
        return f"âŒ è·å–è‚¡ç¥¨æ•°æ®å¤±è´¥: {e}"

# --- 1.1 Unified Stock News ---

def _fetch_news_data(stock_code: str, max_results: int = 10) -> list:
    """å†…éƒ¨è¾…åŠ©å‡½æ•°ï¼šè·å–åŸå§‹æ–°é—»æ•°æ®åˆ—è¡¨"""
    news_list = []

    try:
        from tradingagents.utils.stock_utils import StockUtils
        market_info = StockUtils.get_market_info(stock_code)
        is_china = market_info['is_china']
        is_hk = market_info['is_hk']
        is_us = market_info['is_us']
    except Exception as e:
        logger.warning(f"[MCPæ–°é—»å·¥å…·] è‚¡ç¥¨ç±»å‹è¯†åˆ«å¤±è´¥: {e}")
        is_china, is_hk, is_us = True, False, False

    # 1. ä¼˜å…ˆä»æ•°æ®åº“è·å– (æ‰€æœ‰å¸‚åœº)
    try:
        from tradingagents.dataflows.cache.app_adapter import get_mongodb_client
        client = get_mongodb_client()
        if client:
            db = client.get_database('tradingagents')
            collection = db.stock_news

            clean_code = stock_code.replace('.SH', '').replace('.SZ', '').replace('.SS', '')\
                                   .replace('.XSHE', '').replace('.XSHG', '').replace('.HK', '')

            thirty_days_ago = now_utc() - timedelta(days=30)
            query_list = [
                {'symbol': clean_code, 'publish_time': {'$gte': thirty_days_ago}},
                {'symbol': stock_code, 'publish_time': {'$gte': thirty_days_ago}},
            ]

            for query in query_list:
                cursor = collection.find(query).sort('publish_time', -1).limit(max_results)
                db_items = list(cursor)
                if db_items:
                    logger.info(f"[MCPæ–°é—»å·¥å…·] âœ… æ•°æ®åº“ç¼“å­˜å‘½ä¸­: {len(db_items)} æ¡")
                    for item in db_items:
                        news_list.append({
                            'title': item.get('title', 'æ— æ ‡é¢˜'),
                            'content': item.get('content', '') or item.get('summary', ''),
                            'source': f"{item.get('source', 'æœªçŸ¥')} (DB)",
                            'publish_time': item.get('publish_time', now_utc()),
                            'sentiment': item.get('sentiment', 'neutral'),
                            'url': item.get('url', '')
                        })
                    return news_list
    except Exception as e:
        logger.warning(f"[MCPæ–°é—»å·¥å…·] æ•°æ®åº“è·å–å¤±è´¥: {e}")

    # 2. å¤–éƒ¨æ•°æ®æº

    # --- Aè‚¡ & æ¸¯è‚¡ ---
    if is_china or is_hk:
        clean_code = stock_code.replace('.SH', '').replace('.SZ', '').replace('.SS', '')\
                               .replace('.XSHE', '').replace('.XSHG', '').replace('.HK', '')

        # 2.1 å°è¯• Tushare
        try:
            from tradingagents.dataflows.providers.china.tushare import TushareProvider

            ts_provider = TushareProvider()
            if ts_provider.is_available():
                logger.info(f"ğŸ”„ å°è¯• Tushare æ–°é—»: {stock_code}")
                if hasattr(ts_provider, 'pro') and ts_provider.pro:
                    start_dt = (now_utc() - timedelta(days=30)).strftime('%Y%m%d')
                    end_dt = get_current_date_compact()

                    df = ts_provider.pro.news(src='sina', symbol=clean_code, start_date=start_dt, end_date=end_dt)
                    if df is not None and not df.empty:
                         df = df.sort_values('datetime', ascending=False).head(max_results)

                         for _, row in df.iterrows():
                             news_list.append({
                                 'title': row.get('title', 'æ— æ ‡é¢˜'),
                                 'content': row.get('content', ''),
                                 'source': 'Tushare (Sina)',
                                 'publish_time': row.get('datetime', now_utc()),
                                 'sentiment': 'neutral',
                                 'url': ''
                             })
                         logger.info(f"âœ… Tushare è·å–æ–°é—»æˆåŠŸ: {len(news_list)} æ¡")
                         return news_list
        except Exception as e:
            logger.warning(f"[MCPæ–°é—»å·¥å…·] Tushare è·å–å¤±è´¥: {e}")

        # 2.2 å°è¯• AKShare
        try:
            from tradingagents.dataflows.providers.china.akshare import AKShareProvider
            import asyncio
            import concurrent.futures

            provider = AKShareProvider()

            def run_async():
                loop = asyncio.new_event_loop()
                asyncio.set_event_loop(loop)
                try:
                    return loop.run_until_complete(provider.get_stock_news(symbol=clean_code, limit=max_results))
                finally:
                    loop.close()

            with concurrent.futures.ThreadPoolExecutor(max_workers=1) as executor:
                future = executor.submit(run_async)
                ak_news = future.result(timeout=30)

            if ak_news:
                for item in ak_news:
                    news_list.append({
                        'title': item.get('title', ''),
                        'content': item.get('content', '') or item.get('summary', ''),
                        'source': f"{item.get('source', 'AKShare')}",
                        'publish_time': item.get('publish_time', now_utc()),
                        'sentiment': item.get('sentiment', 'neutral'),
                        'url': item.get('url', '')
                    })
                return news_list
        except Exception as e:
            logger.warning(f"[MCPæ–°é—»å·¥å…·] AKShare è·å–å¤±è´¥: {e}")

    # --- ç¾è‚¡ ---
    if is_us:
        # 2.3 Finnhub
        try:
            from tradingagents.dataflows.interface import get_finnhub_news
            logger.info(f"ğŸ”„ å°è¯• Finnhub æ–°é—»: {stock_code}")
            current_date_str = get_current_date()
            finnhub_news_str = get_finnhub_news(stock_code, current_date_str, 7)

            if finnhub_news_str and "æš‚æ— " not in finnhub_news_str and "Error" not in finnhub_news_str:
                 news_list.append({
                     'title': 'Finnhub News Summary',
                     'content': finnhub_news_str,
                     'source': 'Finnhub',
                     'publish_time': now_utc(),
                     'sentiment': 'neutral'
                 })
                 return news_list
        except Exception as e:
            logger.warning(f"[MCPæ–°é—»å·¥å…·] Finnhub è·å–å¤±è´¥: {e}")

        # 2.4 Google News (Fallback)
        try:
            from tradingagents.dataflows.interface import get_google_news
            logger.info(f"ğŸ”„ å°è¯• Google News: {stock_code}")
            current_date_str = get_current_date()
            google_news_str = get_google_news(stock_code, current_date_str, 7)

            if google_news_str and "æš‚æ— " not in google_news_str:
                 news_list.append({
                     'title': 'Google News Summary',
                     'content': google_news_str,
                     'source': 'Google News',
                     'publish_time': now_utc(),
                     'sentiment': 'neutral'
                 })
                 return news_list
        except Exception as e:
            logger.warning(f"[MCPæ–°é—»å·¥å…·] Google News è·å–å¤±è´¥: {e}")

    return news_list

def _format_news_list(news_list: list, source_label: str = None) -> str:
    """æ ¼å¼åŒ–æ–°é—»åˆ—è¡¨ä¸º Markdown"""
    if not news_list:
        return "æš‚æ— æ–°é—»æ•°æ®"

    report = f"# æœ€æ–°æ–°é—» {'(' + source_label + ')' if source_label else ''}\n\n"
    report += f"ğŸ“… æŸ¥è¯¢æ—¶é—´: {now_utc().strftime('%Y-%m-%d %H:%M:%S')}\n"
    report += f"ğŸ“Š æ–°é—»æ•°é‡: {len(news_list)} æ¡\n\n"

    for i, news in enumerate(news_list, 1):
        title = news.get('title', 'æ— æ ‡é¢˜')
        content = news.get('content', '')
        source = news.get('source', 'æœªçŸ¥æ¥æº')
        pub_time = news.get('publish_time', now_utc())
        if isinstance(pub_time, datetime):
            pub_time_str = pub_time.strftime('%Y-%m-%d %H:%M')
        else:
            pub_time_str = str(pub_time)

        sentiment = news.get('sentiment', 'neutral')
        sentiment_icon = {'positive': 'ğŸ“ˆ', 'negative': 'ğŸ“‰', 'neutral': 'â–'}.get(sentiment, 'â–')

        report += f"## {i}. {sentiment_icon} {title}\n\n"
        report += f"**æ¥æº**: {source} | **æ—¶é—´**: {pub_time_str}\n"
        if sentiment:
            report += f"**æƒ…ç»ª**: {sentiment}\n"
        report += "\n"

        if content:
            if len(content) > 1000 and "===" in content:
                report += content
            else:
                content_preview = content[:500] + '...' if len(content) > 500 else content
                report += f"{content_preview}\n\n"

        report += "---\n\n"

    return report

def get_stock_news(
    stock_code: str,
    max_results: int = 10
) -> str:
    """
    è·å–æŒ‡å®šè‚¡ç¥¨çš„æœ€æ–°æ–°é—»ã€‚

    è¿”å›æ ¼å¼åŒ–çš„æ–°é—»åˆ—è¡¨ï¼ŒåŒ…å«æ ‡é¢˜ã€æ¥æºã€æ—¶é—´å’Œæ‘˜è¦ã€‚

    Args:
        stock_code: è‚¡ç¥¨ä»£ç ï¼Œå¦‚ "000001.SZ"(Aè‚¡)ã€"AAPL"(ç¾è‚¡)ã€"00700.HK"(æ¸¯è‚¡)
        max_results: è¿”å›çš„æœ€å¤§æ–°é—»æ•°ï¼Œå»ºè®®èŒƒå›´ 5-20ï¼Œé»˜è®¤ 10

    Returns:
        JSON æ ¼å¼çš„ ToolResultï¼ŒåŒ…å« statusã€dataã€error_codeã€suggestion å­—æ®µ
    """
    if not stock_code:
        return format_tool_result(error_result(
            ErrorCodes.MISSING_PARAM,
            "æœªæä¾›è‚¡ç¥¨ä»£ç "
        ))

    try:
        news_list = _fetch_news_data(stock_code, max_results)

        if news_list:
            source = news_list[0].get('source', 'Unknown')
            if "(DB)" in source: source_label = "æ•°æ®åº“ç¼“å­˜"
            elif "AKShare" in source: source_label = "AKShare"
            elif "Finnhub" in source: source_label = "Finnhub"
            elif "Google" in source: source_label = "Google News"
            else: source_label = "èšåˆæ•°æ®"

            return format_tool_result(success_result(_format_news_list(news_list, source_label)))

        return format_tool_result(no_data_result(
            message=f"æœªæ‰¾åˆ° {stock_code} çš„æ–°é—»æ•°æ®",
            suggestion="è¿™æ˜¯æ­£å¸¸çŠ¶æ€ï¼Œä¸è¦é‡è¯•æˆ–å°è¯•å…¶ä»–å‚æ•°"
        ))
    except Exception as e:
        logger.error(f"get_stock_news failed: {e}")
        return format_tool_result(error_result(
            ErrorCodes.DATA_FETCH_ERROR,
            str(e)
        ))

def get_stock_fundamentals(
    stock_code: str,
    current_date: str = None,
    start_date: str = None,
    end_date: str = None
) -> str:
    """
    è·å–è‚¡ç¥¨åŸºæœ¬é¢è´¢åŠ¡æ•°æ®å’Œä¼°å€¼æŒ‡æ ‡ã€‚

    è¿”å›åŒ…æ‹¬è´¢åŠ¡æŠ¥è¡¨ã€ä¼°å€¼æŒ‡æ ‡ã€ç›ˆåˆ©èƒ½åŠ›ç­‰åŸºæœ¬é¢æ•°æ®ã€‚

    Args:
        stock_code: è‚¡ç¥¨ä»£ç ï¼Œå¦‚ "000001.SZ"(Aè‚¡)ã€"AAPL"(ç¾è‚¡)ã€"00700.HK"(æ¸¯è‚¡)
        current_date: å½“å‰æ—¥æœŸï¼Œæ ¼å¼ YYYY-MM-DDï¼Œé»˜è®¤ä»Šå¤©
        start_date: å¼€å§‹æ—¥æœŸï¼Œæ ¼å¼ YYYY-MM-DDï¼Œé»˜è®¤ 10 å¤©å‰
        end_date: ç»“æŸæ—¥æœŸï¼Œæ ¼å¼ YYYY-MM-DDï¼Œé»˜è®¤ä»Šå¤©

    Returns:
        JSON æ ¼å¼çš„ ToolResultï¼ŒåŒ…å« statusã€dataã€error_codeã€suggestion å­—æ®µ
    """
    logger.info(f"ğŸ“Š [MCPåŸºæœ¬é¢å·¥å…·] åˆ†æè‚¡ç¥¨: {stock_code}")
    start_time = now_utc()

    # è®¾ç½®é»˜è®¤æ—¥æœŸ
    if not current_date:
        current_date = get_current_date()

    if not start_date:
        start_date = (now_utc() - timedelta(days=10)).strftime('%Y-%m-%d')

    if not end_date:
        end_date = current_date

    # åˆ†çº§åˆ†æå·²åºŸå¼ƒï¼Œç»Ÿä¸€ä½¿ç”¨æ ‡å‡†æ·±åº¦
    data_depth = "standard"

    try:
        from tradingagents.utils.stock_utils import StockUtils

        # è‡ªåŠ¨è¯†åˆ«è‚¡ç¥¨ç±»å‹
        market_info = StockUtils.get_market_info(stock_code)
        is_china = market_info['is_china']
        is_hk = market_info['is_hk']
        is_us = market_info['is_us']

        logger.info(f"ğŸ“Š [MCPåŸºæœ¬é¢å·¥å…·] è‚¡ç¥¨ç±»å‹: {market_info['market_name']}")

        result_data = []

        if is_china:
            # ä¸­å›½Aè‚¡
            logger.info(f"ğŸ‡¨ğŸ‡³ [MCPåŸºæœ¬é¢å·¥å…·] å¤„ç†Aè‚¡æ•°æ®...")

            # è·å–æœ€æ–°è‚¡ä»·ä¿¡æ¯ (ä»…ç”¨äºè¾…åŠ©åˆ†æï¼Œä¸ç›´æ¥è¿”å›)
            current_price_data = ""
            try:
                recent_end_date = current_date
                recent_start_date = (datetime.strptime(current_date, '%Y-%m-%d') - timedelta(days=2)).strftime('%Y-%m-%d')

                from tradingagents.dataflows.interface import get_china_stock_data_unified
                current_price_data = get_china_stock_data_unified(stock_code, recent_start_date, recent_end_date)
            except Exception as e:
                logger.error(f"âŒ [MCPåŸºæœ¬é¢å·¥å…·] Aè‚¡ä»·æ ¼æ•°æ®è·å–å¤±è´¥: {e}")
                current_price_data = ""

            # è·å–åŸºæœ¬é¢è´¢åŠ¡æ•°æ®
            try:
                from tradingagents.dataflows.providers.china.optimized import OptimizedChinaDataProvider
                analyzer = OptimizedChinaDataProvider()

                # æ ¹æ®æ•°æ®æ·±åº¦é€‰æ‹©åˆ†ææ¨¡å—
                analysis_modules = data_depth

                # å°è¯•è°ƒç”¨æŠ¥å‘Šç”Ÿæˆæ–¹æ³•
                if hasattr(analyzer, "generate_fundamentals_report"):
                    fundamentals_data = analyzer.generate_fundamentals_report(stock_code, current_price_data, analysis_modules)
                elif hasattr(analyzer, "_generate_fundamentals_report"):
                    fundamentals_data = analyzer._generate_fundamentals_report(stock_code, current_price_data, analysis_modules)
                else:
                    fundamentals_data = "åŸºæœ¬é¢æŠ¥å‘Šç”Ÿæˆæ–¹æ³•ä¸å¯ç”¨"

                result_data.append(f"## Aè‚¡åŸºæœ¬é¢è´¢åŠ¡æ•°æ®\n{fundamentals_data}")
            except Exception as e:
                logger.error(f"âŒ [MCPåŸºæœ¬é¢å·¥å…·] Aè‚¡åŸºæœ¬é¢æ•°æ®è·å–å¤±è´¥: {e}")
                result_data.append(f"## Aè‚¡åŸºæœ¬é¢è´¢åŠ¡æ•°æ®\nâš ï¸ è·å–å¤±è´¥: {e}")

        elif is_hk:
            # æ¸¯è‚¡
            logger.info(f"ğŸ‡­ğŸ‡° [MCPåŸºæœ¬é¢å·¥å…·] å¤„ç†æ¸¯è‚¡æ•°æ®...")

            # 1. è·å–åŸºç¡€ä¿¡æ¯
            try:
                from tradingagents.dataflows.interface import get_hk_stock_info_unified
                hk_info = get_hk_stock_info_unified(stock_code)

                basic_info = f'''## æ¸¯è‚¡åŸºç¡€ä¿¡æ¯
**åç§°**: {hk_info.get('name', 'N/A')}
**è¡Œä¸š**: {hk_info.get('industry', 'N/A')}
**å¸‚å€¼**: {hk_info.get('market_cap', 'N/A')}
**å¸‚ç›ˆç‡(PE)**: {hk_info.get('pe', 'N/A')}
**å‘¨æ¯ç‡**: {hk_info.get('dividend_yield', 'N/A')}%
'''
                result_data.append(basic_info)
            except Exception as e:
                logger.error(f"âŒ [MCPåŸºæœ¬é¢å·¥å…·] æ¸¯è‚¡åŸºç¡€ä¿¡æ¯è·å–å¤±è´¥: {e}")
                result_data.append(f"## æ¸¯è‚¡åŸºç¡€ä¿¡æ¯\nâš ï¸ è·å–å¤±è´¥: {e}")

        else:
            # ç¾è‚¡
            logger.info(f"ğŸ‡ºğŸ‡¸ [MCPåŸºæœ¬é¢å·¥å…·] å¤„ç†ç¾è‚¡æ•°æ®...")
            try:
                # å°è¯•ä½¿ç”¨ Finnhub è·å–åŸºæœ¬é¢
                try:
                    from tradingagents.dataflows.interface import get_us_stock_info
                    us_info = get_us_stock_info(stock_code)
                    if us_info:
                        result_data.append(f"## ç¾è‚¡åŸºæœ¬é¢ä¿¡æ¯\n{us_info}")
                    else:
                        result_data.append(f"## ç¾è‚¡åŸºæœ¬é¢ä¿¡æ¯\næš‚æ— è¯¦ç»†æ•°æ®")
                except ImportError:
                     result_data.append(f"## ç¾è‚¡åŸºæœ¬é¢ä¿¡æ¯\nâš ï¸ æ¥å£ä¸å¯ç”¨")
            except Exception as e:
                logger.error(f"âŒ [MCPåŸºæœ¬é¢å·¥å…·] ç¾è‚¡æ•°æ®è·å–å¤±è´¥: {e}")
                result_data.append(f"## ç¾è‚¡åŸºæœ¬é¢ä¿¡æ¯\nâš ï¸ è·å–å¤±è´¥: {e}")

        # è®¡ç®—æ‰§è¡Œæ—¶é—´
        execution_time = (now_utc() - start_time).total_seconds()

        # ç»„åˆæ‰€æœ‰æ•°æ®
        combined_result = f"""# {stock_code} åŸºæœ¬é¢åˆ†æ

**è‚¡ç¥¨ç±»å‹**: {market_info['market_name']}
**åˆ†ææ—¥æœŸ**: {current_date}
**æ‰§è¡Œæ—¶é—´**: {execution_time:.2f}ç§’

{chr(10).join(result_data)}
"""
        return format_tool_result(success_result(combined_result))

    except Exception as e:
        logger.error(f"get_stock_fundamentals failed: {e}")
        return format_tool_result(error_result(
            ErrorCodes.DATA_FETCH_ERROR,
            str(e)
        ))

def get_stock_sentiment(
    stock_code: str,
    current_date: str,
    start_date: str = None,
    end_date: str = None,
    source_name: str = None
) -> str:
    """
    è·å–è‚¡ç¥¨å¸‚åœºæƒ…ç»ªåˆ†ææ•°æ®ã€‚

    è¿”å›åŒ…æ‹¬æŠ•èµ„è€…æƒ…ç»ªæŒ‡æ•°ã€ç¤¾äº¤åª’ä½“çƒ­åº¦ã€å†…éƒ¨äººå£«äº¤æ˜“ä¿¡å·ç­‰ã€‚

    Args:
        stock_code: è‚¡ç¥¨ä»£ç ï¼Œå¦‚ "000001.SZ"(Aè‚¡)ã€"AAPL"(ç¾è‚¡)ã€"00700.HK"(æ¸¯è‚¡)
        current_date: å½“å‰æ—¥æœŸï¼Œæ ¼å¼ YYYY-MM-DD
        start_date: ä¿ç•™å‚æ•°ï¼Œæš‚æœªä½¿ç”¨
        end_date: ä¿ç•™å‚æ•°ï¼Œæš‚æœªä½¿ç”¨
        source_name: ä¿ç•™å‚æ•°ï¼Œæš‚æœªä½¿ç”¨

    Returns:
        JSON æ ¼å¼çš„ ToolResultï¼ŒåŒ…å« statusã€dataã€error_codeã€suggestion å­—æ®µ
    """
    # å‚æ•°ä¿ç•™ç”¨äºæœªæ¥æ‰©å±•ï¼Œå½“å‰æœªä½¿ç”¨
    _ = start_date, end_date, source_name
    logger.info(f"ğŸ˜Š [MCPæƒ…ç»ªå·¥å…·] åˆ†æè‚¡ç¥¨: {stock_code}")
    start_time = now_utc()

    try:
        from tradingagents.utils.stock_utils import StockUtils

        # è‡ªåŠ¨è¯†åˆ«è‚¡ç¥¨ç±»å‹
        market_info = StockUtils.get_market_info(stock_code)
        is_china = market_info['is_china']
        is_hk = market_info['is_hk']
        is_us = market_info['is_us']

        logger.info(f"ğŸ˜Š [MCPæƒ…ç»ªå·¥å…·] è‚¡ç¥¨ç±»å‹: {market_info['market_name']}")

        result_data = []

        if is_china or is_hk:
            # ä¸­å›½Aè‚¡å’Œæ¸¯è‚¡ï¼šä½¿ç”¨ç¤¾äº¤åª’ä½“æƒ…ç»ªåˆ†æ
            logger.info(f"ğŸ‡¨ğŸ‡³ğŸ‡­ğŸ‡° [MCPæƒ…ç»ªå·¥å…·] å¤„ç†ä¸­æ–‡å¸‚åœºæƒ…ç»ª...")

            # 1. è·å–æ–°é—»æ•°æ® (å¤ç”¨ get_stock_news çš„é€»è¾‘)
            news_list = _fetch_news_data(stock_code, 20)

            if news_list:
                # ç®€å•è®¡ç®—æƒ…ç»ªåˆ†æ•°
                positive = 0
                negative = 0
                neutral = 0

                for news in news_list:
                    # å¦‚æœæ–°é—»é¡¹æœ¬èº«å¸¦æœ‰ sentiment å­—æ®µï¼ˆAKShareProvider/TushareProvider è¿”å›çš„ï¼‰
                    s = news.get('sentiment', 'neutral')
                    if s == 'positive': positive += 1
                    elif s == 'negative': negative += 1
                    else: neutral += 1

                total = positive + negative + neutral
                score = (positive - negative) / total if total > 0 else 0

                sentiment_summary = f"""
## ä¸­æ–‡å¸‚åœºæƒ…ç»ªåˆ†æ

**è‚¡ç¥¨**: {stock_code} ({market_info['market_name']})
**åˆ†ææ—¥æœŸ**: {current_date}
**åˆ†æå‘¨æœŸ**: è¿‘æœŸæ–°é—»

ğŸ“Š ç»¼åˆæƒ…ç»ªè¯„ä¼°:
å¸‚åœºæƒ…ç»ª: {'ä¹è§‚' if score > 0.2 else 'æ‚²è§‚' if score < -0.2 else 'ä¸­æ€§'} (è¯„åˆ†: {score:.2f}, ç½®ä¿¡åº¦: {'é«˜' if total > 10 else 'ä½'})

ğŸ“° è´¢ç»æ–°é—»æƒ…ç»ª:
- æƒ…ç»ªè¯„åˆ†: {score:.2f}
- æ­£é¢: {positive} æ¡
- è´Ÿé¢: {negative} æ¡
- ä¸­æ€§: {neutral} æ¡
- æ•°æ®æ¥æº: {news_list[0].get('source', 'Unknown')} ç­‰

"""
                result_data.append(sentiment_summary)
            else:
                logger.warning(f"âš ï¸ [MCPæƒ…ç»ªå·¥å…·] ä¸­æ–‡æƒ…ç»ªæ•°æ®ä¸ºç©ºï¼Œå°è¯•å¤‡ç”¨æº")
                # å¤‡ç”¨ï¼šRedditæ–°é—»
                try:
                    from tradingagents.dataflows.interface import get_reddit_company_news
                    reddit_data = get_reddit_company_news(stock_code, current_date, 7, 5)
                    if reddit_data:
                        result_data.append(f"## Redditè®¨è®º(å¤‡ç”¨)\n{reddit_data}")
                except Exception as e:
                    result_data.append(f"## ç¤¾äº¤åª’ä½“æƒ…ç»ª\nâš ï¸ æ•°æ®è·å–å¤±è´¥: {e}")

        else:
            # ç¾è‚¡ï¼šä½¿ç”¨Finnhubå†…å¹•äº¤æ˜“å’Œæƒ…ç»ªæ•°æ®
            logger.info(f"ğŸ‡ºğŸ‡¸ [MCPæƒ…ç»ªå·¥å…·] å¤„ç†ç¾è‚¡å¸‚åœºæƒ…ç»ª...")

            try:
                # å°è¯•è·å–å†…å¹•äº¤æ˜“æƒ…ç»ª
                try:
                    from tradingagents.dataflows.interface import get_finnhub_company_insider_sentiment

                    insider_sentiment = get_finnhub_company_insider_sentiment(stock_code, current_date, 30)
                    if insider_sentiment:
                        result_data.append(f"## å†…éƒ¨äººå£«æƒ…ç»ª\n{insider_sentiment}")
                except Exception as e:
                    logger.warning(f"âš ï¸ [MCPæƒ…ç»ªå·¥å…·] å†…å¹•äº¤æ˜“æ•°æ®è·å–å¤±è´¥: {e}")

                # å°è¯•è·å–Redditè®¨è®º
                try:
                    from tradingagents.dataflows.interface import get_reddit_company_news
                    reddit_info = get_reddit_company_news(stock_code, current_date, 7, 5)
                    if reddit_info:
                        result_data.append(f"## Redditè®¨è®º\n{reddit_info}")
                except Exception as e:
                    logger.warning(f"âš ï¸ [MCPæƒ…ç»ªå·¥å…·] Redditæ•°æ®è·å–å¤±è´¥: {e}")

                if not result_data:
                    result_data.append("## å¸‚åœºæƒ…ç»ªåˆ†æ\næš‚æ— æ•°æ®")

            except Exception as e:
                logger.error(f"âŒ [MCPæƒ…ç»ªå·¥å…·] ç¾è‚¡æƒ…ç»ªè·å–å¤±è´¥: {e}")
                result_data.append(f"## å¸‚åœºæƒ…ç»ªåˆ†æ\næš‚æ— æ•°æ® (æ•°æ®æºè®¿é—®å¼‚å¸¸)")

        # è®¡ç®—æ‰§è¡Œæ—¶é—´
        execution_time = (now_utc() - start_time).total_seconds()

        # ç»„åˆæ‰€æœ‰æ•°æ®
        combined_result = f"""# {stock_code} å¸‚åœºæƒ…ç»ªåˆ†æ

**è‚¡ç¥¨ç±»å‹**: {market_info['market_name']}
**åˆ†ææ—¥æœŸ**: {current_date}
**æ‰§è¡Œæ—¶é—´**: {execution_time:.2f}ç§’

{chr(10).join(result_data)}

---
*æ•°æ®æ¥æº: ç¤¾äº¤åª’ä½“ã€æ–°é—»è¯„è®ºåŠå†…éƒ¨äº¤æ˜“æ•°æ®*
"""
        return format_tool_result(success_result(combined_result))

    except Exception as e:
        logger.error(f"get_stock_sentiment failed: {e}")
        return format_tool_result(error_result(
            ErrorCodes.DATA_FETCH_ERROR,
            str(e)
        ))

def get_china_market_overview(
    date: str = None,
    include_indices: bool = True,
    include_sectors: bool = True
) -> str:
    """
    è·å–ä¸­å›½Aè‚¡å¸‚åœºæ•´ä½“æ¦‚è§ˆã€‚

    è¿”å›å¸‚åœºæŒ‡æ•°ã€æ¿å—è¡¨ç°ã€èµ„é‡‘æµå‘ç­‰å®è§‚å¸‚åœºæ•°æ®ã€‚

    Args:
        date: æŸ¥è¯¢æ—¥æœŸï¼Œæ ¼å¼ YYYY-MM-DDï¼Œé»˜è®¤ä»Šå¤©
        include_indices: æ˜¯å¦åŒ…å«ä¸»è¦æŒ‡æ•°æ•°æ®ï¼ˆä¸Šè¯ã€æ·±è¯ã€åˆ›ä¸šæ¿ç­‰ï¼‰
        include_sectors: æ˜¯å¦åŒ…å«æ¿å—è¡¨ç°æ•°æ®

    Returns:
        JSON æ ¼å¼çš„ ToolResultï¼ŒåŒ…å« statusã€dataã€error_codeã€suggestion å­—æ®µ
    """
    logger.info(f"ğŸ‡¨ğŸ‡³ [MCPä¸­å›½å¸‚åœºå·¥å…·] è·å–å¸‚åœºæ¦‚è§ˆ")
    start_time = now_utc()

    if not date:
        date = get_current_date()

    result_sections = []

    # è·å–ä¸»è¦æŒ‡æ•°æ•°æ®
    if include_indices:
        indices_data = []
        indices_source = "Unknown"

        # å®šä¹‰å…³æ³¨çš„æŒ‡æ•°
        indices_to_fetch = [
            ('000001.SH', 'sh000001', 'ä¸Šè¯æŒ‡æ•°'),
            ('399001.SZ', 'sz399001', 'æ·±è¯æˆæŒ‡'),
            ('399006.SZ', 'sz399006', 'åˆ›ä¸šæ¿æŒ‡')
        ]

        # 1. å°è¯•ä½¿ç”¨ get_manager().get_index_data (æ”¯æŒ DB -> Tushare -> AKShare)
        try:
            for ts_code, ak_code, name in indices_to_fetch:
                # ä¼˜å…ˆå°è¯• Tushare æ ¼å¼ä»£ç 
                try:
                    # ä½¿ç”¨ DataSourceManager çš„é€»è¾‘
                    index_result = get_manager().get_index_data(code=ts_code, start_date=date, end_date=date)

                    # ç®€å•è§£æè¿”å›çš„ Markdown è¡¨æ ¼è·å–æ”¶ç›˜ä»·
                    if index_result and "|" in index_result:
                        lines = index_result.split('\n')
                        # å¯»æ‰¾åŒ…å«æ—¥æœŸçš„è¡Œ
                        data_line = None
                        for line in lines:
                            if date.replace('-', '') in line or date in line:
                                data_line = line
                                break

                        if data_line:
                            indices_data.append(f"- **{name}**: (å·²è·å–ï¼Œè¯·æŸ¥çœ‹è¯¦ç»†æŒ‡æ•°æ•°æ®)")
                            continue
                except Exception:
                    pass

                # å¦‚æœä¸Šé¢å¤±è´¥ï¼Œå°è¯• AKShare ç›´æ¥è°ƒç”¨ (ä½œä¸ºå¤‡ç”¨)
                try:
                    import akshare as ak
                    df = ak.stock_zh_index_daily(symbol=ak_code)
                    if not df.empty:
                        latest = df.iloc[-1]
                        close = latest.get('close', 'N/A')
                        indices_data.append(f"- **{name}**: {close}")
                        indices_source = "AKShare"
                except Exception as e:
                    logger.warning(f"è·å– {name} å¤±è´¥: {e}")

        except Exception as e:
            logger.warning(f"è·å–æŒ‡æ•°æ•°æ®å¼‚å¸¸: {e}")

        if indices_data:
            result_sections.append(f"## ä¸»è¦æŒ‡æ•°\n\n" + "\n".join(indices_data))
        else:
            result_sections.append("## ä¸»è¦æŒ‡æ•°\n\nâš ï¸ æŒ‡æ•°æ•°æ®æš‚æ—¶æ— æ³•è·å–")

    # è·å–æ¿å—è¡¨ç° (AKShare)
    if include_sectors:
        try:
            import akshare as ak
            import concurrent.futures

            # ä½¿ç”¨çº¿ç¨‹æ± å’Œè¶…æ—¶æœºåˆ¶æ‰§è¡Œ AKShare è°ƒç”¨ï¼Œé˜²æ­¢é˜»å¡
            def fetch_sector_data():
                # ç›´æ¥è°ƒç”¨ï¼Œå¼‚å¸¸ç”± future.result() æŠ›å‡ºå¹¶åœ¨ä¸»çº¿ç¨‹æ•è·
                return ak.stock_board_industry_name_em()

            sector_df = None
            try:
                with concurrent.futures.ThreadPoolExecutor(max_workers=1) as executor:
                    future = executor.submit(fetch_sector_data)
                    sector_df = future.result(timeout=15)  # 15ç§’è¶…æ—¶
            except concurrent.futures.TimeoutError:
                logger.warning("AKShare æ¿å—æ•°æ®è·å–è¶…æ—¶ (15s)")
                result_sections.append("## æ¿å—è¡¨ç°\n\nâš ï¸ æ•°æ®è·å–è¶…æ—¶ï¼Œè¯·ç¨åé‡è¯•")
            except Exception as e:
                logger.warning(f"AKShare æ¿å—æ•°æ®è·å–å¼‚å¸¸: {e}")
                result_sections.append(f"## æ¿å—è¡¨ç°\n\nâš ï¸ æ•°æ®æºå¼‚å¸¸: {e}")

            if sector_df is not None and not sector_df.empty:
                # å–æ¶¨å¹…å‰5å’Œè·Œå¹…å‰5
                top_sectors = sector_df.head(5)
                bottom_sectors = sector_df.tail(5)

                sector_info = "## æ¿å—è¡¨ç° (AKShare)\n\n"
                sector_info += "### æ¶¨å¹…å‰5\n"
                for _, row in top_sectors.iterrows():
                    name = row.get('æ¿å—åç§°', 'N/A')
                    change = row.get('æ¶¨è·Œå¹…', 'N/A')
                    sector_info += f"- {name}: {change}%\n"

                sector_info += "\n### è·Œå¹…å‰5\n"
                for _, row in bottom_sectors.iterrows():
                    name = row.get('æ¿å—åç§°', 'N/A')
                    change = row.get('æ¶¨è·Œå¹…', 'N/A')
                    sector_info += f"- {name}: {change}%\n"

                result_sections.append(sector_info)
            elif sector_df is None:
                # é”™è¯¯ä¿¡æ¯å·²åœ¨ä¸Šé¢æ·»åŠ 
                pass
            else:
                result_sections.append("## æ¿å—è¡¨ç°\n\nâš ï¸ æ¿å—æ•°æ®æš‚æ—¶æ— æ³•è·å– (ç©ºæ•°æ®)")

        except Exception as e:
            logger.error(f"âŒ [MCPä¸­å›½å¸‚åœºå·¥å…·] è·å–æ¿å—æ•°æ®å¤±è´¥: {e}")
            result_sections.append(f"## æ¿å—è¡¨ç°\n\nâš ï¸ è·å–å¤±è´¥: {e}")

    # è®¡ç®—æ‰§è¡Œæ—¶é—´
    execution_time = (now_utc() - start_time).total_seconds()

    # ç»„åˆç»“æœ
    combined_result = f"""# ä¸­å›½Aè‚¡å¸‚åœºæ¦‚è§ˆ

**æŸ¥è¯¢æ—¥æœŸ**: {date}
**æ‰§è¡Œæ—¶é—´**: {execution_time:.2f}ç§’

{chr(10).join(result_sections)}

---
*æ•°æ®æ¥æº: AKShare/Tushare*
"""
    logger.info(f"ğŸ‡¨ğŸ‡³ [MCPä¸­å›½å¸‚åœºå·¥å…·] æ•°æ®è·å–å®Œæˆï¼Œæ€»é•¿åº¦: {len(combined_result)}")
    return format_tool_result(success_result(combined_result))

def get_stock_data_minutes(
    market_type: str,
    stock_code: str,
    start_datetime: Optional[str] = None,
    end_datetime: Optional[str] = None,
    freq: str = "30min"
) -> str:
    """
    è·å–åˆ†é’Ÿçº§ K çº¿æ•°æ®ã€‚

    Args:
        market_type: å¸‚åœºç±»å‹ï¼Œç›®å‰ä»…æ”¯æŒ "cn"
        stock_code: è‚¡ç¥¨ä»£ç ï¼Œå¦‚ "600519.SH"
        start_datetime: å¼€å§‹æ—¶é—´ï¼Œæ ¼å¼ YYYY-MM-DD HH:mm:ss æˆ– YYYYMMDDHHmmssï¼Œé»˜è®¤ 1 å¤©å‰
        end_datetime: ç»“æŸæ—¶é—´ï¼Œæ ¼å¼ YYYY-MM-DD HH:mm:ss æˆ– YYYYMMDDHHmmssï¼Œé»˜è®¤ç°åœ¨
        freq: é¢‘ç‡ï¼Œæ”¯æŒ "1min"ã€"5min"ã€"15min"ã€"30min"ã€"60min"ï¼Œé»˜è®¤ "30min"

    Returns:
        JSON æ ¼å¼çš„ ToolResultï¼ŒåŒ…å« statusã€dataã€error_codeã€suggestion å­—æ®µ
    """
    try:
        # è®¾ç½®é»˜è®¤æ—¶é—´
        if not end_datetime:
            end_datetime = now_utc().strftime('%Y-%m-%d %H:%M:%S')
        if not start_datetime:
            start_datetime = (now_utc() - timedelta(days=1)).strftime('%Y-%m-%d %H:%M:%S')

        # ğŸ”¥ ä¼˜å…ˆä½¿ç”¨Tushareè·å–åˆ†é’Ÿçº§è¡Œæƒ…æ•°æ®
        try:
            logger.info(f"ğŸ“Š å°è¯•ä½¿ç”¨Tushareè·å–åˆ†é’Ÿçº§è¡Œæƒ…: {stock_code}, é¢‘ç‡: {freq}")
            data = get_manager().get_stock_data_minutes(
                market_type=market_type,
                code=stock_code,
                start_datetime=start_datetime,
                end_datetime=end_datetime,
                freq=freq
            )
            if data and not data.empty:
                logger.info(f"âœ… TushareæˆåŠŸè·å–åˆ†é’Ÿçº§è¡Œæƒ…: {stock_code}, {len(data)}æ¡è®°å½•")
                return format_tool_result(success_result(_format_result(data, f"{stock_code} {freq} Data")))
        except Exception as tu_e:
            logger.info(f"âš ï¸ Tushareè·å–åˆ†é’Ÿçº§è¡Œæƒ…å¤±è´¥: {tu_e}ï¼Œå°è¯•AkShare")

        # å›é€€åˆ°AkShare
        if market_type == "cn":
            try:
                import akshare as ak
                import pandas as pd

                # é¢‘ç‡æ˜ å°„
                freq_map = {
                    "1min": "1",
                    "5min": "5",
                    "15min": "15",
                    "30min": "30",
                    "60min": "60"
                }
                period = freq_map.get(freq, "30")

                # æ ‡å‡†åŒ–è‚¡ç¥¨ä»£ç ä¸º6ä½
                code_6digit = stock_code.replace('.SH', '').replace('.SZ', '').replace('.sh', '').replace('.sz', '').zfill(6)

                logger.info(f"ğŸ“Š å°è¯•ä½¿ç”¨AkShareè·å–åˆ†é’Ÿçº§è¡Œæƒ…: {stock_code}, é¢‘ç‡: {freq}")

                # è·å–åˆ†é’Ÿçº§æ•°æ®
                df = ak.stock_zh_a_hist_min_em(symbol=code_6digit, period=period, adjust="")

                if df is not None and not df.empty:
                    logger.info(f"âœ… AkShareæˆåŠŸè·å–åˆ†é’Ÿçº§è¡Œæƒ…: {stock_code}, {len(df)}æ¡è®°å½•")

                    # æ ¼å¼åŒ–æ•°æ®
                    result_text = f"# {stock_code} åˆ†é’Ÿçº§è¡Œæƒ…ï¼ˆæ¥æºï¼šAkShareï¼‰\n\n"
                    result_text += f"**é¢‘ç‡**: {freq}\n"
                    result_text += f"**è®°å½•æ•°**: {len(df)}\n"
                    result_text += f"**æ—¶é—´èŒƒå›´**: {df.iloc[0]['æ—¶é—´']} è‡³ {df.iloc[-1]['æ—¶é—´']}\n\n"

                    result_text += "## è¡Œæƒ…æ˜ç»†ï¼ˆå‰50æ¡ï¼‰\n\n"
                    for idx, row in df.head(50).iterrows():
                        result_text += f"### {row['æ—¶é—´']}\n"
                        result_text += f"- **å¼€ç›˜**: {row['å¼€ç›˜']}\n"
                        result_text += f"- **æ”¶ç›˜**: {row['æ”¶ç›˜']}\n"
                        result_text += f"- **æœ€é«˜**: {row['æœ€é«˜']}\n"
                        result_text += f"- **æœ€ä½**: {row['æœ€ä½']}\n"
                        result_text += f"- **æˆäº¤é‡**: {row['æˆäº¤é‡']}\n"
                        result_text += f"- **æˆäº¤é¢**: {row['æˆäº¤é¢']}\n"
                        result_text += f"- **æ¶¨è·Œå¹…**: {row['æ¶¨è·Œå¹…']}\n"
                        result_text += f"- **æ¶¨è·Œé¢**: {row['æ¶¨è·Œé¢']}\n"
                        result_text += f"- **æŒ¯å¹…**: {row['æŒ¯å¹…']}\n\n"

                    return result_text
                else:
                    logger.warning(f"âš ï¸ AkShareæœªè·å–åˆ°åˆ†é’Ÿçº§è¡Œæƒ…æ•°æ®")
            except Exception as ak_e:
                logger.warning(f"âš ï¸ AkShareè·å–åˆ†é’Ÿçº§è¡Œæƒ…å¤±è´¥: {ak_e}")

        # ä¸¤ä¸ªæ•°æ®æºéƒ½å¤±è´¥
        return format_tool_result(error_result(
            ErrorCodes.DATA_FETCH_ERROR,
            f"æ— æ³•ä»Tushareå’ŒAkShareè·å–åˆ†é’Ÿçº§è¡Œæƒ…æ•°æ®: {stock_code}"
        ))
    except Exception as e:
        logger.error(f"get_stock_data_minutes failed: {e}")
        return format_tool_result(error_result(
            ErrorCodes.DATA_FETCH_ERROR,
            str(e)
        ))

# --- 2. Company Performance ---

def get_company_performance(
    stock_code: str,
    data_type: str,
    start_date: Optional[str] = None,
    end_date: Optional[str] = None,
    period: Optional[str] = None
) -> str:
    """
    è·å– A è‚¡å…¬å¸ä¸šç»©å’Œè´¢åŠ¡æ•°æ®ã€‚

    Args:
        stock_code: è‚¡ç¥¨ä»£ç ï¼Œå¦‚ "000001.SZ"
        data_type: æ•°æ®ç±»å‹ï¼Œæ”¯æŒ forecast(ä¸šç»©é¢„å‘Š)ã€express(ä¸šç»©å¿«æŠ¥)ã€indicators(è´¢åŠ¡æŒ‡æ ‡)ã€dividend(åˆ†çº¢é€è½¬)ç­‰
        start_date: å¼€å§‹æ—¥æœŸï¼Œæ ¼å¼ YYYYMMDDï¼Œé»˜è®¤ 1 å¹´å‰
        end_date: ç»“æŸæ—¥æœŸï¼Œæ ¼å¼ YYYYMMDDï¼Œé»˜è®¤ä»Šå¤©
        period: æŠ¥å‘ŠæœŸï¼Œæ ¼å¼ YYYYMMDDï¼Œå¯é€‰

    Returns:
        JSON æ ¼å¼çš„ ToolResultï¼ŒåŒ…å« statusã€dataã€error_codeã€suggestion å­—æ®µ
    """
    try:
        # è®¾ç½®é»˜è®¤æ—¥æœŸ
        if not end_date:
            end_date = get_current_date_compact()
        if not start_date:
            start_date = (now_utc() - timedelta(days=360)).strftime('%Y%m%d')

        # ğŸ”¥ ä¼˜å…ˆä½¿ç”¨Tushareè·å–ä¸šç»©æ•°æ®
        try:
            logger.info(f"ğŸ“Š å°è¯•ä½¿ç”¨Tushareè·å–ä¸šç»©æ•°æ®: {stock_code}, data_type: {data_type}")
            data = get_manager().get_company_performance(
                stock_code=stock_code,
                data_type=data_type,
                start_date=start_date,
                end_date=end_date,
                period=period
            )
            if data and not data.empty:
                logger.info(f"âœ… TushareæˆåŠŸè·å–ä¸šç»©æ•°æ®: {stock_code}, {len(data)}æ¡è®°å½•")
                return format_tool_result(success_result(_format_result(data, f"{stock_code} Performance ({data_type})")))
        except Exception as tu_e:
            logger.info(f"âš ï¸ Tushareè·å–ä¸šç»©æ•°æ®å¤±è´¥: {tu_e}ï¼Œå°è¯•AkShare")

        # å›é€€åˆ°AkShareï¼ˆä»…æ”¯æŒä¸šç»©é¢„å‘Šforecastï¼‰
        if data_type == "forecast":
            try:
                import akshare as ak
                import pandas as pd

                # æ ‡å‡†åŒ–è‚¡ç¥¨ä»£ç ä¸º6ä½
                code_6digit = stock_code.replace('.SH', '').replace('.SZ', '').replace('.sh', '').replace('.sz', '').zfill(6)

                logger.info(f"ğŸ“Š å°è¯•ä½¿ç”¨AkShareè·å–ä¸šç»©é¢„å‘Š: {stock_code}")

                # è·å–ä¸šç»©é¢„å‘Šæ•°æ®
                df = ak.stock_profit_forecast_em()

                if df is not None and not df.empty:
                    # è¿‡æ»¤æŒ‡å®šè‚¡ç¥¨çš„æ•°æ®
                    df_filtered = df[df['ä»£ç '] == code_6digit]

                    if not df_filtered.empty:
                        logger.info(f"âœ… AkShareæˆåŠŸè·å–ä¸šç»©é¢„å‘Šæ•°æ®: {stock_code}")

                        # æ ¼å¼åŒ–æ•°æ®
                        result_text = f"# {stock_code} ä¸šç»©é¢„å‘Šæ•°æ®ï¼ˆæ¥æºï¼šAkShare-ä¸œæ–¹è´¢å¯Œï¼‰\n\n"

                        for idx, row in df_filtered.iterrows():
                            result_text += f"## {row.get('åç§°', stock_code)}\n\n"
                            result_text += f"**è‚¡ç¥¨ä»£ç **: {row.get('ä»£ç ', stock_code)}\n"
                            result_text += f"**ç ”æŠ¥æ•°**: {row.get('ç ”æŠ¥æ•°', 'N/A')}\n\n"

                            result_text += "### æœºæ„æŠ•èµ„è¯„çº§ï¼ˆè¿‘å…­ä¸ªæœˆï¼‰\n"
                            result_text += f"- **ä¹°å…¥**: {row.get('æœºæ„æŠ•èµ„è¯„çº§(è¿‘å…­ä¸ªæœˆ)-ä¹°å…¥', 'N/A')}\n"
                            result_text += f"- **å¢æŒ**: {row.get('æœºæ„æŠ•èµ„è¯„çº§(è¿‘å…­ä¸ªæœˆ)-å¢æŒ', 'N/A')}\n"
                            result_text += f"- **ä¸­æ€§**: {row.get('æœºæ„æŠ•èµ„è¯„çº§(è¿‘å…­ä¸ªæœˆ)-ä¸­æ€§', 'N/A')}\n"
                            result_text += f"- **å‡æŒ**: {row.get('æœºæ„æŠ•èµ„è¯„çº§(è¿‘å…­ä¸ªæœˆ)-å‡æŒ', 'N/A')}\n"
                            result_text += f"- **å–å‡º**: {row.get('æœºæ„æŠ•èµ„è¯„çº§(è¿‘å…­ä¸ªæœˆ)-å–å‡º', 'N/A')}\n\n"

                            result_text += "### é¢„æµ‹æ¯è‚¡æ”¶ç›Š\n"
                            for year in ['2024', '2025', '2026', '2027']:
                                eps_key = f"{year}é¢„æµ‹æ¯è‚¡æ”¶ç›Š"
                                if eps_key in row and pd.notna(row[eps_key]):
                                    result_text += f"- **{year}å¹´**: {row[eps_key]:.2f}å…ƒ\n"

                            result_text += "\n"

                        return result_text
                    else:
                        logger.warning(f"âš ï¸ AkShareæœªæ‰¾åˆ°{stock_code}çš„ä¸šç»©é¢„å‘Šæ•°æ®")
                else:
                    logger.warning(f"âš ï¸ AkShareä¸šç»©é¢„å‘Šæ¥å£è¿”å›ç©ºæ•°æ®")
            except Exception as ak_e:
                logger.warning(f"âš ï¸ AkShareè·å–ä¸šç»©é¢„å‘Šå¤±è´¥: {ak_e}")

        # ä¸¤ä¸ªæ•°æ®æºéƒ½å¤±è´¥
        return format_tool_result(error_result(
            ErrorCodes.DATA_FETCH_ERROR,
            f"æ— æ³•ä»Tushareå’ŒAkShareè·å–ä¸šç»©æ•°æ®: {stock_code}, data_type: {data_type}"
        ))
    except Exception as e:
        logger.error(f"get_company_performance failed: {e}")
        return format_tool_result(error_result(
            ErrorCodes.DATA_FETCH_ERROR,
            str(e)
        ))

def get_company_performance_hk(
    stock_code: str,
    data_type: str,
    start_date: Optional[str] = None,
    end_date: Optional[str] = None,
    period: Optional[str] = None,
    ind_name: Optional[str] = None
) -> str:
    """
    è·å–æ¸¯è‚¡è´¢åŠ¡æ•°æ®ã€‚

    Args:
        stock_code: æ¸¯è‚¡ä»£ç ï¼Œå¦‚ "00700.HK"
        data_type: æ•°æ®ç±»å‹ï¼Œæ”¯æŒ income(åˆ©æ¶¦è¡¨)ã€balance(èµ„äº§è´Ÿå€ºè¡¨)ã€cashflow(ç°é‡‘æµé‡è¡¨)
        start_date: å¼€å§‹æ—¥æœŸï¼Œæ ¼å¼ YYYYMMDDï¼Œé»˜è®¤ 1 å¹´å‰
        end_date: ç»“æŸæ—¥æœŸï¼Œæ ¼å¼ YYYYMMDDï¼Œé»˜è®¤ä»Šå¤©
        period: æŠ¥å‘ŠæœŸï¼Œå¯é€‰
        ind_name: æŒ‡æ ‡åç§°è¿‡æ»¤ï¼Œå¯é€‰

    Returns:
        JSON æ ¼å¼çš„ ToolResultï¼ŒåŒ…å« statusã€dataã€error_codeã€suggestion å­—æ®µ
    """
    try:
        # è®¾ç½®é»˜è®¤æ—¥æœŸ
        if not end_date:
            end_date = get_current_date_compact()
        if not start_date:
            start_date = (now_utc() - timedelta(days=360)).strftime('%Y%m%d')

        # ğŸ”¥ ä¼˜å…ˆä½¿ç”¨Tushareè·å–æ¸¯è‚¡æ•°æ®
        try:
            logger.info(f"ğŸ“Š å°è¯•ä½¿ç”¨Tushareè·å–æ¸¯è‚¡æ•°æ®: {stock_code}, data_type: {data_type}")
            data = get_manager().get_company_performance(
                ts_code=stock_code,
                data_type=data_type,
                start_date=start_date,
                end_date=end_date,
                period=period,
                ind_name=ind_name,
                market="hk"
            )
            if data and not data.empty:
                logger.info(f"âœ… TushareæˆåŠŸè·å–æ¸¯è‚¡æ•°æ®: {stock_code}, {len(data)}æ¡è®°å½•")
                return format_tool_result(success_result(_format_result(data, f"{stock_code} {data_type} (HK)")))
        except Exception as tu_e:
            logger.info(f"âš ï¸ Tushareè·å–æ¸¯è‚¡æ•°æ®å¤±è´¥: {tu_e}ï¼Œå°è¯•AkShare")

        # å›é€€åˆ°AkShareï¼ˆä»…æ”¯æŒä¸šç»©é¢„å‘Šforecastï¼‰
        if data_type == "forecast":
            try:
                import akshare as ak
                import pandas as pd

                # æ ‡å‡†åŒ–æ¸¯è‚¡ä»£ç ï¼ˆç§»é™¤.HKåç¼€ï¼‰
                code_clean = stock_code.replace('.HK', '').replace('.hk', '').zfill(5)

                logger.info(f"ğŸ“Š å°è¯•ä½¿ç”¨AkShareè·å–æ¸¯è‚¡ä¸šç»©é¢„å‘Š: {stock_code}")

                # è·å–æ¸¯è‚¡ä¸šç»©é¢„æµ‹
                df = ak.stock_hk_profit_forecast_et(symbol=code_clean)

                if df is not None and not df.empty:
                    logger.info(f"âœ… AkShareæˆåŠŸè·å–æ¸¯è‚¡ä¸šç»©é¢„å‘Š: {stock_code}")

                    # æ ¼å¼åŒ–æ•°æ®
                    result_text = f"# {stock_code} æ¸¯è‚¡ä¸šç»©é¢„å‘Šï¼ˆæ¥æºï¼šAkShare-ä¸œæ–¹è´¢å¯Œï¼‰\n\n"
                    result_text += f"**è®°å½•æ•°**: {len(df)}\n\n"

                    result_text += "## ä¸šç»©é¢„å‘Šæ˜ç»†\n\n"
                    for idx, row in df.iterrows():
                        result_text += f"### è®°å½• {idx + 1}\n"
                        for col in df.columns:
                            value = row[col]
                            if pd.notna(value):
                                result_text += f"- **{col}**: {value}\n"
                        result_text += "\n"

                    return result_text
                else:
                    logger.warning(f"âš ï¸ AkShareæœªè·å–åˆ°æ¸¯è‚¡ä¸šç»©é¢„å‘Š")
            except Exception as ak_e:
                logger.warning(f"âš ï¸ AkShareè·å–æ¸¯è‚¡ä¸šç»©é¢„å‘Šå¤±è´¥: {ak_e}")

        # ä¸¤ä¸ªæ•°æ®æºéƒ½å¤±è´¥
        return format_tool_result(error_result(
            ErrorCodes.DATA_FETCH_ERROR,
            f"æ— æ³•ä»Tushareå’ŒAkShareè·å–æ¸¯è‚¡æ•°æ®: {stock_code}, data_type: {data_type}"
        ))
    except Exception as e:
        logger.error(f"get_company_performance_hk failed: {e}")
        return format_tool_result(error_result(
            ErrorCodes.DATA_FETCH_ERROR,
            str(e)
        ))

def get_company_performance_us(
    stock_code: str,
    data_type: str,
    start_date: Optional[str] = None,
    end_date: Optional[str] = None,
    period: Optional[str] = None
) -> str:
    """
    è·å–ç¾è‚¡è´¢åŠ¡æ•°æ®ã€‚

    Args:
        stock_code: ç¾è‚¡ä»£ç ï¼Œå¦‚ "AAPL"
        data_type: æ•°æ®ç±»å‹ï¼Œæ”¯æŒ income(åˆ©æ¶¦è¡¨)ã€balance(èµ„äº§è´Ÿå€ºè¡¨)ã€cashflow(ç°é‡‘æµé‡è¡¨)ã€indicator(è´¢åŠ¡æŒ‡æ ‡)
        start_date: å¼€å§‹æ—¥æœŸï¼Œæ ¼å¼ YYYYMMDDï¼Œé»˜è®¤ 1 å¹´å‰
        end_date: ç»“æŸæ—¥æœŸï¼Œæ ¼å¼ YYYYMMDDï¼Œé»˜è®¤ä»Šå¤©
        period: æŠ¥å‘ŠæœŸï¼Œå¯é€‰

    Returns:
        JSON æ ¼å¼çš„ ToolResultï¼ŒåŒ…å« statusã€dataã€error_codeã€suggestion å­—æ®µ
    """
    try:
        # è®¾ç½®é»˜è®¤æ—¥æœŸ
        if not end_date:
            end_date = get_current_date_compact()
        if not start_date:
            start_date = (now_utc() - timedelta(days=360)).strftime('%Y%m%d')

        data = get_manager().get_company_performance(
            ts_code=stock_code,
            data_type=data_type,
            start_date=start_date,
            end_date=end_date,
            period=period,
            market="us"
        )
        return format_tool_result(success_result(_format_result(data, f"{stock_code} {data_type} (US)")))
    except Exception as e:
        logger.error(f"get_company_performance_us failed: {e}")
        return format_tool_result(error_result(
            ErrorCodes.DATA_FETCH_ERROR,
            str(e)
        ))

# --- 3. Macro & Flows ---

def get_macro_econ(
    indicator: str,
    start_date: Optional[str] = None,
    end_date: Optional[str] = None
) -> str:
    """
    è·å–å®è§‚ç»æµæ•°æ®ã€‚

    Args:
        indicator: æŒ‡æ ‡åç§°ï¼Œæ”¯æŒ shiborã€lprã€gdpã€cpiã€ppiã€cn_mã€cn_pmiã€cn_sf ç­‰
        start_date: å¼€å§‹æ—¥æœŸï¼Œæ ¼å¼ YYYYMMDDï¼Œé»˜è®¤ 3 ä¸ªæœˆå‰
        end_date: ç»“æŸæ—¥æœŸï¼Œæ ¼å¼ YYYYMMDDï¼Œé»˜è®¤ä»Šå¤©

    Returns:
        JSON æ ¼å¼çš„ ToolResultï¼ŒåŒ…å« statusã€dataã€error_codeã€suggestion å­—æ®µ
    """
    try:
        # è®¾ç½®é»˜è®¤æ—¥æœŸ
        if not end_date:
            end_date = get_current_date_compact()
        if not start_date:
            start_date = (now_utc() - timedelta(days=90)).strftime('%Y%m%d')

        data = get_manager().get_macro_econ(indicator=indicator, start_date=start_date, end_date=end_date)
        return format_tool_result(success_result(_format_result(data, f"Macro: {indicator}")))
    except Exception as e:
        logger.error(f"get_macro_econ failed: {e}")
        return format_tool_result(error_result(
            ErrorCodes.DATA_FETCH_ERROR,
            str(e)
        ))

def get_money_flow(
    start_date: Optional[str] = None,
    end_date: Optional[str] = None,
    query_type: Optional[str] = None,
    ts_code: Optional[str] = None,
    content_type: Optional[str] = None,
    trade_date: Optional[str] = None
) -> str:
    """
    è·å–èµ„é‡‘æµå‘æ•°æ®ã€‚

    Args:
        start_date: å¼€å§‹æ—¥æœŸï¼Œæ ¼å¼ YYYYMMDDï¼Œé»˜è®¤ 1 ä¸ªæœˆå‰
        end_date: ç»“æŸæ—¥æœŸï¼Œæ ¼å¼ YYYYMMDDï¼Œé»˜è®¤ä»Šå¤©
        query_type: æŸ¥è¯¢ç±»å‹ï¼Œæ”¯æŒ stock(ä¸ªè‚¡)ã€market(å¤§ç›˜)ã€sector(æ¿å—)
        ts_code: è‚¡ç¥¨æˆ–æ¿å—ä»£ç 
        content_type: æ¿å—ç±»å‹ï¼Œæ”¯æŒ industry(è¡Œä¸š)ã€concept(æ¦‚å¿µ)ã€area(åœ°åŸŸ)
        trade_date: æŒ‡å®šäº¤æ˜“æ—¥æœŸï¼Œæ ¼å¼ YYYYMMDD

    Returns:
        JSON æ ¼å¼çš„ ToolResultï¼ŒåŒ…å« statusã€dataã€error_codeã€suggestion å­—æ®µ
    """
    try:
        # è®¾ç½®é»˜è®¤æ—¥æœŸ (å¦‚æœæœªæä¾› trade_date)
        if not trade_date:
            if not end_date:
                end_date = get_current_date_compact()
            if not start_date:
                start_date = (now_utc() - timedelta(days=30)).strftime('%Y%m%d')

        data = get_manager().get_money_flow(
            start_date=start_date,
            end_date=end_date,
            query_type=query_type,
            ts_code=ts_code,
            content_type=content_type,
            trade_date=trade_date
        )
        return format_tool_result(success_result(_format_result(data, f"Money Flow: {ts_code or query_type}")))
    except Exception as e:
        logger.error(f"get_money_flow failed: {e}")
        return format_tool_result(error_result(
            ErrorCodes.DATA_FETCH_ERROR,
            str(e)
        ))

def get_margin_trade(
    data_type: str,
    start_date: Optional[str] = None,
    end_date: Optional[str] = None,
    ts_code: Optional[str] = None,
    exchange: Optional[str] = None
) -> str:
    """
    è·å–èèµ„èåˆ¸æ•°æ®ã€‚

    Args:
        data_type: æ•°æ®ç±»å‹ï¼Œæ”¯æŒ margin_secsã€marginã€margin_detailã€slb_len_mm
        start_date: å¼€å§‹æ—¥æœŸï¼Œæ ¼å¼ YYYYMMDDï¼Œé»˜è®¤ 1 ä¸ªæœˆå‰
        end_date: ç»“æŸæ—¥æœŸï¼Œæ ¼å¼ YYYYMMDDï¼Œé»˜è®¤ä»Šå¤©
        ts_code: è‚¡ç¥¨ä»£ç 
        exchange: äº¤æ˜“æ‰€ï¼Œæ”¯æŒ SSEã€SZSEã€BSE

    Returns:
        JSON æ ¼å¼çš„ ToolResultï¼ŒåŒ…å« statusã€dataã€error_codeã€suggestion å­—æ®µ
    """
    try:
        # è®¾ç½®é»˜è®¤æ—¥æœŸ
        if not end_date:
            end_date = get_current_date_compact()
        if not start_date:
            start_date = (now_utc() - timedelta(days=30)).strftime('%Y%m%d')

        # ğŸ”¥ ä¼˜å…ˆä½¿ç”¨Tushareè·å–èèµ„èåˆ¸æ•°æ®
        try:
            logger.info(f"ğŸ“Š å°è¯•ä½¿ç”¨Tushareè·å–èèµ„èåˆ¸æ•°æ®: {data_type}")
            data = get_manager().get_margin_trade(
                data_type=data_type,
                start_date=start_date,
                end_date=end_date,
                ts_code=ts_code,
                exchange=exchange
            )
            if data and not data.empty:
                logger.info(f"âœ… TushareæˆåŠŸè·å–èèµ„èåˆ¸æ•°æ®: {data_type}, {len(data)}æ¡è®°å½•")
                return format_tool_result(success_result(_format_result(data, f"Margin Trade: {data_type}")))
        except Exception as tu_e:
            logger.info(f"âš ï¸ Tushareè·å–èèµ„èåˆ¸æ•°æ®å¤±è´¥: {tu_e}ï¼Œå°è¯•AkShare")

        # å›é€€åˆ°AkShareï¼ˆæš‚ä¸æ”¯æŒèèµ„èåˆ¸æ˜ç»†æ•°æ®ï¼‰
        # AkShareä¸æä¾›ä¸ªè‚¡èèµ„èåˆ¸æ˜ç»†æ¥å£ï¼Œä»…æä¾›èèµ„èåˆ¸æ±‡æ€»æ•°æ®
        logger.info(f"âš ï¸ AkShareæš‚ä¸æ”¯æŒä¸ªè‚¡èèµ„èåˆ¸æ˜ç»†æ•°æ®ï¼Œä»…Tushareæ”¯æŒ")

        # ä¸¤ä¸ªæ•°æ®æºéƒ½å¤±è´¥
        return format_tool_result(error_result(
            ErrorCodes.DATA_FETCH_ERROR,
            f"æ— æ³•ä»Tushareå’ŒAkShareè·å–èèµ„èåˆ¸æ•°æ®: {data_type}"
        ))
    except Exception as e:
        logger.error(f"get_margin_trade failed: {e}")
        return format_tool_result(error_result(
            ErrorCodes.DATA_FETCH_ERROR,
            str(e)
        ))

# --- 4. Funds ---

def get_fund_data(
    ts_code: str,
    data_type: str,
    start_date: Optional[str] = None,
    end_date: Optional[str] = None,
    period: Optional[str] = None
) -> str:
    """
    è·å–å…¬å‹ŸåŸºé‡‘æ•°æ®ã€‚

    Args:
        ts_code: åŸºé‡‘ä»£ç 
        data_type: æ•°æ®ç±»å‹ï¼Œæ”¯æŒ basicã€managerã€navã€dividendã€portfolioã€all
        start_date: å¼€å§‹æ—¥æœŸï¼Œæ ¼å¼ YYYYMMDDï¼Œé»˜è®¤ 3 ä¸ªæœˆå‰
        end_date: ç»“æŸæ—¥æœŸï¼Œæ ¼å¼ YYYYMMDDï¼Œé»˜è®¤ä»Šå¤©
        period: æŠ¥å‘ŠæœŸï¼Œå¯é€‰

    Returns:
        JSON æ ¼å¼çš„ ToolResultï¼ŒåŒ…å« statusã€dataã€error_codeã€suggestion å­—æ®µ
    """
    try:
        # è®¾ç½®é»˜è®¤æ—¥æœŸ
        if not end_date:
            end_date = get_current_date_compact()
        if not start_date:
            start_date = (now_utc() - timedelta(days=90)).strftime('%Y%m%d')

        # ğŸ”¥ ä¼˜å…ˆä½¿ç”¨Tushareè·å–åŸºé‡‘æ•°æ®
        try:
            logger.info(f"ğŸ“Š å°è¯•ä½¿ç”¨Tushareè·å–åŸºé‡‘æ•°æ®: {ts_code}, ç±»å‹: {data_type}")
            data = get_manager().get_fund_data(
                ts_code=ts_code,
                data_type=data_type,
                start_date=start_date,
                end_date=end_date,
                period=period
            )
            if data and not data.empty:
                logger.info(f"âœ… TushareæˆåŠŸè·å–åŸºé‡‘æ•°æ®: {ts_code}, {len(data)}æ¡è®°å½•")
                return format_tool_result(success_result(_format_result(data, f"Fund: {ts_code} {data_type}")))
        except Exception as tu_e:
            logger.info(f"âš ï¸ Tushareè·å–åŸºé‡‘æ•°æ®å¤±è´¥: {tu_e}ï¼Œå°è¯•AkShare")

        # å›é€€åˆ°AkShareï¼ˆä»…æ”¯æŒbasicã€navã€allç±»å‹ï¼‰
        if data_type in ["basic", "nav", "all"]:
            try:
                import akshare as ak
                import pandas as pd

                logger.info(f"ğŸ“Š å°è¯•ä½¿ç”¨AkShareè·å–åŸºé‡‘æ•°æ®: {ts_code}, ç±»å‹: {data_type}")

                # è·å–åŸºé‡‘ä¿¡æ¯ï¼ˆæ³¨æ„ï¼šfund_open_fund_info_emä¸éœ€è¦yearå‚æ•°ï¼‰
                df = ak.fund_open_fund_info_em(symbol=ts_code)

                if df is not None and not df.empty:
                    logger.info(f"âœ… AkShareæˆåŠŸè·å–åŸºé‡‘æ•°æ®: {ts_code}")

                    # æ ¼å¼åŒ–æ•°æ®
                    result_text = f"# {ts_code} åŸºé‡‘æ•°æ®ï¼ˆæ¥æºï¼šAkShareï¼‰\n\n"
                    result_text += f"**æ•°æ®ç±»å‹**: {data_type}\n\n"

                    result_text += "## åŸºé‡‘ä¿¡æ¯\n\n"
                    for col in df.columns:
                        value = df.iloc[0][col]
                        # å¤„ç†NaNå€¼
                        if pd.notna(value):
                            result_text += f"- **{col}**: {value}\n"

                    return result_text
                else:
                    logger.warning(f"âš ï¸ AkShareæœªè·å–åˆ°åŸºé‡‘æ•°æ®")
            except Exception as ak_e:
                logger.warning(f"âš ï¸ AkShareè·å–åŸºé‡‘æ•°æ®å¤±è´¥: {ak_e}")

        # ä¸¤ä¸ªæ•°æ®æºéƒ½å¤±è´¥
        return format_tool_result(error_result(
            ErrorCodes.DATA_FETCH_ERROR,
            f"æ— æ³•ä»Tushareå’ŒAkShareè·å–åŸºé‡‘æ•°æ®: {ts_code}, data_type: {data_type}"
        ))
    except Exception as e:
        logger.error(f"get_fund_data failed: {e}")
        return format_tool_result(error_result(
            ErrorCodes.DATA_FETCH_ERROR,
            str(e)
        ))

def get_fund_manager_by_name(
    name: str,
    ann_date: Optional[str] = None
) -> str:
    """
    æ ¹æ®å§“åè·å–åŸºé‡‘ç»ç†ä¿¡æ¯ã€‚

    Args:
        name: åŸºé‡‘ç»ç†å§“å
        ann_date: å…¬å‘Šæ—¥æœŸï¼Œæ ¼å¼ YYYYMMDDï¼Œå¯é€‰

    Returns:
        JSON æ ¼å¼çš„ ToolResultï¼ŒåŒ…å« statusã€dataã€error_codeã€suggestion å­—æ®µ
    """
    try:
        data = get_manager().get_fund_manager_by_name(name=name, ann_date=ann_date)
        return format_tool_result(success_result(_format_result(data, f"Manager: {name}")))
    except Exception as e:
        logger.error(f"get_fund_manager_by_name failed: {e}")
        return format_tool_result(error_result(
            ErrorCodes.DATA_FETCH_ERROR,
            str(e)
        ))

# --- 5. Index & Others ---

def get_index_data(
    stock_code: str,
    start_date: Optional[str] = None,
    end_date: Optional[str] = None
) -> str:
    """
    è·å–æŒ‡æ•°æ—¥çº¿è¡Œæƒ…ã€‚

    Args:
        stock_code: æŒ‡æ•°ä»£ç ï¼Œå¦‚ "000001.SH"
        start_date: å¼€å§‹æ—¥æœŸï¼Œæ ¼å¼ YYYYMMDDï¼Œé»˜è®¤ 3 ä¸ªæœˆå‰
        end_date: ç»“æŸæ—¥æœŸï¼Œæ ¼å¼ YYYYMMDDï¼Œé»˜è®¤ä»Šå¤©

    Returns:
        JSON æ ¼å¼çš„ ToolResultï¼ŒåŒ…å« statusã€dataã€error_codeã€suggestion å­—æ®µ
    """
    try:
        # è®¾ç½®é»˜è®¤æ—¥æœŸ
        if not end_date:
            end_date = get_current_date_compact()
        if not start_date:
            start_date = (now_utc() - timedelta(days=90)).strftime('%Y%m%d')

        data = get_manager().get_index_data(code=stock_code, start_date=start_date, end_date=end_date)
        return format_tool_result(success_result(_format_result(data, f"Index: {stock_code}")))
    except Exception as e:
        logger.error(f"get_index_data failed: {e}")
        return format_tool_result(error_result(
            ErrorCodes.DATA_FETCH_ERROR,
            str(e)
        ))

def get_csi_index_constituents(
    index_code: str,
    start_date: Optional[str] = None,
    end_date: Optional[str] = None
) -> str:
    """
    è·å–ä¸­è¯æŒ‡æ•°æˆä»½è‚¡åŠæƒé‡ã€‚

    Args:
        index_code: æŒ‡æ•°ä»£ç 
        start_date: å¼€å§‹æ—¥æœŸï¼Œæ ¼å¼ YYYYMMDDï¼Œé»˜è®¤ 1 ä¸ªæœˆå‰
        end_date: ç»“æŸæ—¥æœŸï¼Œæ ¼å¼ YYYYMMDDï¼Œé»˜è®¤ä»Šå¤©

    Returns:
        JSON æ ¼å¼çš„ ToolResultï¼ŒåŒ…å« statusã€dataã€error_codeã€suggestion å­—æ®µ
    """
    try:
        # è®¾ç½®é»˜è®¤æ—¥æœŸ
        if not end_date:
            end_date = get_current_date_compact()
        if not start_date:
            start_date = (now_utc() - timedelta(days=30)).strftime('%Y%m%d')

        data = get_manager().get_csi_index_constituents(index_code=index_code, start_date=start_date, end_date=end_date)
        return format_tool_result(success_result(_format_result(data, f"CSI Constituents: {index_code}")))
    except Exception as e:
        logger.error(f"get_csi_index_constituents failed: {e}")
        return format_tool_result(error_result(
            ErrorCodes.DATA_FETCH_ERROR,
            str(e)
        ))

def get_convertible_bond(
    data_type: str,
    ts_code: Optional[str] = None,
    start_date: Optional[str] = None,
    end_date: Optional[str] = None
) -> str:
    """
    è·å–å¯è½¬å€ºæ•°æ®ã€‚

    Args:
        data_type: æ•°æ®ç±»å‹ï¼Œæ”¯æŒ issue(å‘è¡Œä¿¡æ¯)ã€info(åŸºæœ¬ä¿¡æ¯)
        ts_code: è½¬å€ºä»£ç 
        start_date: å¼€å§‹æ—¥æœŸï¼Œæ ¼å¼ YYYYMMDD
        end_date: ç»“æŸæ—¥æœŸï¼Œæ ¼å¼ YYYYMMDD

    Returns:
        JSON æ ¼å¼çš„ ToolResultï¼ŒåŒ…å« statusã€dataã€error_codeã€suggestion å­—æ®µ
    """
    try:
        # ğŸ”¥ ä¼˜å…ˆä½¿ç”¨Tushareè·å–å¯è½¬å€ºæ•°æ®
        try:
            logger.info(f"ğŸ“Š å°è¯•ä½¿ç”¨Tushareè·å–å¯è½¬å€ºæ•°æ®: ç±»å‹{data_type}")
            data = get_manager().get_convertible_bond(
                data_type=data_type,
                ts_code=ts_code,
                start_date=start_date,
                end_date=end_date
            )
            if data and not data.empty:
                logger.info(f"âœ… TushareæˆåŠŸè·å–å¯è½¬å€ºæ•°æ®: {len(data)}æ¡è®°å½•")
                return format_tool_result(success_result(_format_result(data, f"CB: {data_type}")))
        except Exception as tu_e:
            logger.info(f"âš ï¸ Tushareè·å–å¯è½¬å€ºæ•°æ®å¤±è´¥: {tu_e}ï¼Œå°è¯•AkShare")

        # å›é€€åˆ°AkShare
        try:
            import akshare as ak
            import pandas as pd

            logger.info(f"ğŸ“Š å°è¯•ä½¿ç”¨AkShareè·å–å¯è½¬å€ºæ•°æ®: ç±»å‹{data_type}")

            # è·å–å¯è½¬å€ºæ•°æ®
            df = ak.bond_cb_jsl()

            if df is not None and not df.empty:
                logger.info(f"âœ… AkShareæˆåŠŸè·å–å¯è½¬å€ºæ•°æ®: {len(df)}æ¡è®°å½•")

                # å¦‚æœæŒ‡å®šäº†è½¬å€ºä»£ç ï¼Œè¿›è¡Œè¿‡æ»¤
                if ts_code:
                    df_filtered = df[df['å€ºåˆ¸ä»£ç '] == ts_code]

                    if df_filtered.empty:
                        logger.info(f"âš ï¸ AkShareæœªæ‰¾åˆ°{ts_code}çš„å¯è½¬å€ºæ•°æ®ï¼Œè¿”å›å…¨éƒ¨æ•°æ®")
                        df_filtered = df
                    else:
                        logger.info(f"âœ… AkShareæ‰¾åˆ°{ts_code}çš„å¯è½¬å€ºæ•°æ®")
                else:
                    df_filtered = df

                # æ ¼å¼åŒ–æ•°æ®ï¼ˆé™åˆ¶æœ€å¤šæ˜¾ç¤º50æ¡ï¼‰
                result_text = f"# å¯è½¬å€ºæ•°æ®ï¼ˆæ¥æºï¼šAkShare-é›†æ€å½•ï¼‰\n\n"
                result_text += f"**æ•°æ®ç±»å‹**: {data_type}\n"
                if ts_code:
                    result_text += f"**å€ºåˆ¸ä»£ç **: {ts_code}\n"
                result_text += f"**è®°å½•æ•°**: {len(df_filtered)}\n\n"

                result_text += "## å¯è½¬å€ºæ˜ç»†ï¼ˆå‰50æ¡ï¼‰\n\n"
                for idx, row in df_filtered.head(50).iterrows():
                    result_text += f"### å€ºåˆ¸ {idx + 1}\n"
                    for col in df_filtered.columns:
                        value = row[col]
                        if pd.notna(value):
                            result_text += f"- **{col}**: {value}\n"
                    result_text += "\n"

                return result_text
            else:
                logger.warning(f"âš ï¸ AkShareå¯è½¬å€ºæ¥å£è¿”å›ç©ºæ•°æ®")
        except Exception as ak_e:
            logger.warning(f"âš ï¸ AkShareè·å–å¯è½¬å€ºæ•°æ®å¤±è´¥: {ak_e}")

        # ä¸¤ä¸ªæ•°æ®æºéƒ½å¤±è´¥
        return format_tool_result(error_result(
            ErrorCodes.DATA_FETCH_ERROR,
            f"æ— æ³•ä»Tushareå’ŒAkShareè·å–å¯è½¬å€ºæ•°æ®: {data_type}"
        ))
    except Exception as e:
        logger.error(f"get_convertible_bond failed: {e}")
        return format_tool_result(error_result(
            ErrorCodes.DATA_FETCH_ERROR,
            str(e)
        ))

def get_block_trade(
    start_date: Optional[str] = None,
    end_date: Optional[str] = None,
    code: Optional[str] = None
) -> str:
    """
    è·å–å¤§å®—äº¤æ˜“æ•°æ®ã€‚

    Args:
        start_date: å¼€å§‹æ—¥æœŸï¼Œæ ¼å¼ YYYYMMDDï¼Œé»˜è®¤ 7 å¤©å‰
        end_date: ç»“æŸæ—¥æœŸï¼Œæ ¼å¼ YYYYMMDDï¼Œé»˜è®¤ä»Šå¤©
        code: è‚¡ç¥¨ä»£ç ï¼Œå¯é€‰

    Returns:
        JSON æ ¼å¼çš„ ToolResultï¼ŒåŒ…å« statusã€dataã€error_codeã€suggestion å­—æ®µ
    """
    try:
        # è®¾ç½®é»˜è®¤æ—¥æœŸ
        if not end_date:
            end_date = get_current_date_compact()
        if not start_date:
            start_date = (now_utc() - timedelta(days=7)).strftime('%Y%m%d')

        # ğŸ”¥ ä¼˜å…ˆä½¿ç”¨Tushareè·å–å¤§å®—äº¤æ˜“æ•°æ®
        try:
            logger.info(f"ğŸ“Š å°è¯•ä½¿ç”¨Tushareè·å–å¤§å®—äº¤æ˜“æ•°æ®")
            data = get_manager().get_block_trade(start_date=start_date, end_date=end_date, code=code)
            if data and not data.empty:
                logger.info(f"âœ… TushareæˆåŠŸè·å–å¤§å®—äº¤æ˜“æ•°æ®: {len(data)}æ¡è®°å½•")
                return format_tool_result(success_result(_format_result(data, f"Block Trade: {code or 'All'}")))
        except Exception as tu_e:
            logger.info(f"âš ï¸ Tushareè·å–å¤§å®—äº¤æ˜“æ•°æ®å¤±è´¥: {tu_e}ï¼Œå°è¯•AkShare")

        # å›é€€åˆ°AkShare
        try:
            import akshare as ak
            import pandas as pd

            logger.info(f"ğŸ“Š å°è¯•ä½¿ç”¨AkShareè·å–å¤§å®—äº¤æ˜“æ•°æ®")

            # AkShareå¤§å®—äº¤æ˜“æ¥å£ï¼šå°è¯•å¤šä¸ªæ¥å£
            try:
                # ä¼˜å…ˆå°è¯•æ–°æ¥å£
                df = ak.stock_block_trade(start_date=start_date, end_date=end_date)
            except (AttributeError, Exception):
                # å›é€€åˆ°æ—§æ¥å£
                try:
                    df = ak.stock_dzjy_hygtj(date=start_date.replace('-', ''))
                except:
                    # å°è¯•ä¸œæ–¹è´¢å¯Œæ¥å£
                    df = ak.stock_block_deal_em(date=start_date.replace('-', ''))

            if df is not None and not df.empty:
                logger.info(f"âœ… AkShareæˆåŠŸè·å–å¤§å®—äº¤æ˜“æ•°æ®: {len(df)}æ¡è®°å½•")

                # å¦‚æœæŒ‡å®šäº†è‚¡ç¥¨ä»£ç ï¼Œè¿›è¡Œè¿‡æ»¤
                if code:
                    code_6digit = code.replace('.SH', '').replace('.SZ', '').replace('.sh', '').replace('.sz', '').zfill(6)
                    # å°è¯•å¤šç§å¯èƒ½çš„åˆ—å
                    for col_name in ['è‚¡ç¥¨ä»£ç ', 'ä»£ç ', 'symbol', 'stock_code']:
                        if col_name in df.columns:
                            df_filtered = df[df[col_name] == code_6digit]
                            if not df_filtered.empty:
                                break
                    else:
                        df_filtered = df

                    if df_filtered.empty:
                        logger.info(f"âš ï¸ AkShareæœªæ‰¾åˆ°{code}çš„å¤§å®—äº¤æ˜“æ•°æ®ï¼Œè¿”å›å…¨éƒ¨æ•°æ®")
                        df_filtered = df
                    else:
                        logger.info(f"âœ… AkShareæ‰¾åˆ°{code}çš„å¤§å®—äº¤æ˜“æ•°æ®: {len(df_filtered)}æ¡è®°å½•")
                else:
                    df_filtered = df

                # æ ¼å¼åŒ–æ•°æ®ï¼ˆé™åˆ¶æœ€å¤šæ˜¾ç¤º50æ¡ï¼‰
                result_text = f"# å¤§å®—äº¤æ˜“æ•°æ®ï¼ˆæ¥æºï¼šAkShareï¼‰\n\n"
                result_text += f"**æ—¥æœŸèŒƒå›´**: {start_date} è‡³ {end_date}\n"
                if code:
                    result_text += f"**è‚¡ç¥¨ä»£ç **: {code}\n"
                result_text += f"**è®°å½•æ•°**: {len(df_filtered)}\n\n"

                result_text += "## å¤§å®—äº¤æ˜“æ˜ç»†ï¼ˆå‰50æ¡ï¼‰\n\n"
                for idx, row in df_filtered.head(50).iterrows():
                    result_text += f"### äº¤æ˜“ {idx + 1}\n"
                    for col in df_filtered.columns:
                        value = row[col]
                        # æ ¼å¼åŒ–æ•°å€¼
                        if pd.notna(value):
                            result_text += f"- **{col}**: {value}\n"
                    result_text += "\n"

                return result_text
            else:
                logger.warning(f"âš ï¸ AkShareå¤§å®—äº¤æ˜“æ¥å£è¿”å›ç©ºæ•°æ®")
        except Exception as ak_e:
            logger.warning(f"âš ï¸ AkShareè·å–å¤§å®—äº¤æ˜“æ•°æ®å¤±è´¥: {ak_e}")

        # ä¸¤ä¸ªæ•°æ®æºéƒ½å¤±è´¥
        return format_tool_result(error_result(
            ErrorCodes.DATA_FETCH_ERROR,
            f"æ— æ³•ä»Tushareå’ŒAkShareè·å–å¤§å®—äº¤æ˜“æ•°æ®"
        ))
    except Exception as e:
        logger.error(f"get_block_trade failed: {e}")
        return format_tool_result(error_result(
            ErrorCodes.DATA_FETCH_ERROR,
            str(e)
        ))

def get_dragon_tiger_inst(
    trade_date: Optional[str] = None,
    ts_code: Optional[str] = None
) -> str:
    """
    è·å–é¾™è™æ¦œæœºæ„æ˜ç»†ã€‚

    Args:
        trade_date: äº¤æ˜“æ—¥æœŸï¼Œæ ¼å¼ YYYYMMDDï¼Œé»˜è®¤ä»Šå¤©
        ts_code: è‚¡ç¥¨ä»£ç ï¼Œå¯é€‰

    Returns:
        JSON æ ¼å¼çš„ ToolResultï¼ŒåŒ…å« statusã€dataã€error_codeã€suggestion å­—æ®µ
    """
    try:
        # è®¾ç½®é»˜è®¤æ—¥æœŸ
        if not trade_date:
            trade_date = get_current_date_compact()

        # ğŸ”¥ ä¼˜å…ˆä½¿ç”¨Tushareè·å–é¾™è™æ¦œæ•°æ®
        try:
            logger.info(f"ğŸ“Š å°è¯•ä½¿ç”¨Tushareè·å–é¾™è™æ¦œæ•°æ®: æ—¥æœŸ{trade_date}")
            data = get_manager().get_dragon_tiger_inst(trade_date=trade_date, ts_code=ts_code)
            if data and not data.empty:
                logger.info(f"âœ… TushareæˆåŠŸè·å–é¾™è™æ¦œæ•°æ®: {len(data)}æ¡è®°å½•")
                return format_tool_result(success_result(_format_result(data, f"Dragon Tiger: {trade_date}")))
        except Exception as tu_e:
            logger.info(f"âš ï¸ Tushareè·å–é¾™è™æ¦œæ•°æ®å¤±è´¥: {tu_e}ï¼Œå°è¯•AkShare")

        # å›é€€åˆ°AkShare
        try:
            import akshare as ak
            import pandas as pd

            logger.info(f"ğŸ“Š å°è¯•ä½¿ç”¨AkShareè·å–é¾™è™æ¦œæ•°æ®: æ—¥æœŸ{trade_date}")

            # è·å–é¾™è™æ¦œæ¯æ—¥è¯¦æƒ…ï¼ˆæ·»åŠ å†…éƒ¨é”™è¯¯å¤„ç†ï¼‰
            try:
                df = ak.stock_lhb_detail_daily_sina(date=trade_date)
            except KeyError as ke:
                # AkShareå†…éƒ¨bugï¼š'è‚¡ç¥¨ä»£ç 'å­—æ®µç¼ºå¤±
                logger.warning(f"âš ï¸ AkShareé¾™è™æ¦œæ¥å£å†…éƒ¨é”™è¯¯: {ke}ï¼Œå°è¯•å…¶ä»–æ¥å£")
                try:
                    # å°è¯•ä½¿ç”¨ä¸œæ–¹è´¢å¯Œé¾™è™æ¦œæ¥å£
                    df = ak.stock_lhb_detail_em(date=trade_date)
                except:
                    logger.warning(f"âš ï¸ æ‰€æœ‰AkShareé¾™è™æ¦œæ¥å£å‡å¤±è´¥")
                    df = None

            if df is not None and not df.empty:
                # å¦‚æœæŒ‡å®šäº†è‚¡ç¥¨ä»£ç ï¼Œè¿›è¡Œè¿‡æ»¤
                if ts_code:
                    code_6digit = ts_code.replace('.SH', '').replace('.SZ', '').replace('.sh', '').replace('.sz', '').zfill(6)
                    # å°è¯•å¤šç§å¯èƒ½çš„åˆ—å
                    df_filtered = None
                    for col_name in ['ä»£ç ', 'è‚¡ç¥¨ä»£ç ', 'symbol', 'stock_code']:
                        if col_name in df.columns:
                            df_filtered = df[df[col_name] == code_6digit]
                            if not df_filtered.empty:
                                break

                    if df_filtered is None or df_filtered.empty:
                        logger.info(f"âš ï¸ AkShareæœªæ‰¾åˆ°{ts_code}çš„é¾™è™æ¦œæ•°æ®ï¼Œè¿”å›å…¨éƒ¨æ•°æ®")
                        df_filtered = df
                    else:
                        logger.info(f"âœ… AkShareæ‰¾åˆ°{ts_code}çš„é¾™è™æ¦œæ•°æ®: {len(df_filtered)}æ¡è®°å½•")
                else:
                    df_filtered = df

                logger.info(f"âœ… AkShareæˆåŠŸè·å–é¾™è™æ¦œæ•°æ®: {len(df_filtered)}æ¡è®°å½•")

                # æ ¼å¼åŒ–æ•°æ®ï¼ˆé™åˆ¶æœ€å¤šæ˜¾ç¤º50æ¡ï¼‰
                result_text = f"# é¾™è™æ¦œæ•°æ®ï¼ˆæ¥æºï¼šAkShareï¼‰\n\n"
                result_text += f"**äº¤æ˜“æ—¥æœŸ**: {trade_date}\n"
                if ts_code:
                    result_text += f"**è‚¡ç¥¨ä»£ç **: {ts_code}\n"
                result_text += f"**è®°å½•æ•°**: {len(df_filtered)}\n\n"

                result_text += "## é¾™è™æ¦œæ˜ç»†ï¼ˆå‰50æ¡ï¼‰\n\n"
                for idx, row in df_filtered.head(50).iterrows():
                    result_text += f"### è®°å½• {idx + 1}\n"
                    for col in df_filtered.columns:
                        value = row[col]
                        if pd.notna(value):
                            result_text += f"- **{col}**: {value}\n"
                    result_text += "\n"

                return result_text
            else:
                logger.warning(f"âš ï¸ AkShareé¾™è™æ¦œæ¥å£è¿”å›ç©ºæ•°æ®")
        except Exception as ak_e:
            logger.warning(f"âš ï¸ AkShareè·å–é¾™è™æ¦œæ•°æ®å¤±è´¥: {ak_e}")

        # ä¸¤ä¸ªæ•°æ®æºéƒ½å¤±è´¥
        return format_tool_result(error_result(
            ErrorCodes.DATA_FETCH_ERROR,
            f"æ— æ³•ä»Tushareå’ŒAkShareè·å–é¾™è™æ¦œæ•°æ®: {trade_date}"
        ))
    except Exception as e:
        logger.error(f"get_dragon_tiger_inst failed: {e}")
        return format_tool_result(error_result(
            ErrorCodes.DATA_FETCH_ERROR,
            str(e)
        ))

# --- 6. News ---

def get_finance_news(
    query: str
) -> str:
    """
    æœç´¢è´¢ç»æ–°é—»ã€‚

    Args:
        query: æœç´¢å…³é”®è¯

    Returns:
        JSON æ ¼å¼çš„ ToolResultï¼ŒåŒ…å« statusã€dataã€error_codeã€suggestion å­—æ®µ
    """
    try:
        data = get_manager().get_finance_news(query=query)
        return format_tool_result(success_result(_format_result(data, f"News: {query}")))
    except Exception as e:
        logger.error(f"get_finance_news failed: {e}")
        return format_tool_result(error_result(
            ErrorCodes.DATA_FETCH_ERROR,
            str(e)
        ))

def get_hot_news_7x24(
    limit: int = 100
) -> str:
    """
    è·å– 7x24 å°æ—¶å…¨çƒè´¢ç»å¿«è®¯ã€‚

    Args:
        limit: è·å–æ¡æ•°ï¼Œé»˜è®¤ 100

    Returns:
        JSON æ ¼å¼çš„ ToolResultï¼ŒåŒ…å« statusã€dataã€error_codeã€suggestion å­—æ®µ
    """
    try:
        data = get_manager().get_hot_news_7x24(limit=limit)
        return format_tool_result(success_result(_format_result(data, "Hot News 7x24")))
    except Exception as e:
        logger.error(f"get_hot_news_7x24 failed: {e}")
        return format_tool_result(error_result(
            ErrorCodes.DATA_FETCH_ERROR,
            str(e)
        ))

def get_current_timestamp(
    format: str = "%Y-%m-%d %H:%M:%S"
) -> str:
    """
    è·å–å½“å‰æ—¶é—´æˆ³ã€‚

    Args:
        format: æ ¼å¼å­—ç¬¦ä¸²ï¼Œé»˜è®¤ "%Y-%m-%d %H:%M:%S"

    Returns:
        å½“å‰æ—¶é—´æˆ³å­—ç¬¦ä¸²
    """
    return format_tool_result(success_result(now_utc().strftime(format)))

# --- Helpers ---

def _format_result(data: Any, title: str, max_rows: int = 2000) -> str:
    """Format data to Markdown"""
    if data is None:
        return f"# {title}\n\nNo data found."

    if isinstance(data, list) and not data:
        return f"# {title}\n\nNo data found."

    if isinstance(data, str):
        # å¦‚æœå­—ç¬¦ä¸²æœ¬èº«å·²ç»æ˜¯Markdownè¡¨æ ¼ï¼Œå°è¯•æˆªæ–­è¡Œæ•°
        if "|" in data and data.count('\n') > max_rows + 5:
            lines = data.split('\n')
            # ä¿ç•™å¤´éƒ¨å’Œå‰ max_rows è¡Œ
            # å‡è®¾å‰ä¸¤è¡Œæ˜¯è¡¨å¤´
            header = lines[:2]
            content = lines[2:]
            if len(content) > max_rows:
                truncated_content = content[:max_rows]
                return "\n".join(header + truncated_content + [f"\n... (å‰©ä½™ {len(content) - max_rows} è¡Œå·²éšè—)"])
        return data

    # Assuming data is a list of dicts or a pandas DataFrame (converted to list of dicts)
    if isinstance(data, list) and len(data) > 0 and isinstance(data[0], dict):
        # Truncate list if too long
        original_len = len(data)
        if original_len > max_rows:
            data = data[:max_rows]

        # Create markdown table
        headers = list(data[0].keys())
        header_row = "| " + " | ".join(headers) + " |"
        separator_row = "| " + " | ".join(["---"] * len(headers)) + " |"

        rows = []
        for item in data:
            row = "| " + " | ".join([str(item.get(h, "")) for h in headers]) + " |"
            rows.append(row)

        result = f"# {title}\n\n{header_row}\n{separator_row}\n" + "\n".join(rows)

        if original_len > max_rows:
            result += f"\n\n... (å‰©ä½™ {original_len - max_rows} è¡Œå·²éšè—)"

        return result

    return f"# {title}\n\n{str(data)}"
